{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "args_perm_id = 0\n",
    "args_task_num = 5\n",
    "args_class_num = 10\n",
    "args_shot_num = 5\n",
    "def collect_from_json(dataset, root, split):\n",
    "    if split == \"train\":\n",
    "        pth = os.path.join(\n",
    "            root,\n",
    "            dataset,\n",
    "            \"perm\" + str(args_perm_id),\n",
    "            f\"{dataset}_{args_task_num}task_{args_class_num // args_task_num}way_{args_shot_num}shot.{split}.jsonl\",\n",
    "        )\n",
    "    elif split in [\"dev\", \"test\"]:\n",
    "        pth = os.path.join(root, dataset, f\"{dataset}.{split}.jsonl\")\n",
    "    elif split == \"stream\":\n",
    "        pth = os.path.join(\n",
    "            root,\n",
    "            dataset,\n",
    "            f\"stream_label_{args_task_num}task_{args_class_num // args_task_num}way.json\",\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f'Split \"{split}\" value wrong!')\n",
    "    if not os.path.exists(pth):\n",
    "        raise FileNotFoundError(f\"Path {pth} do not exist!\")\n",
    "    else:\n",
    "        with open(pth) as f:\n",
    "            if pth.endswith(\".jsonl\"):\n",
    "                data = [json.loads(line) for line in f]\n",
    "                if split == \"train\":\n",
    "                    data = [list(i.values()) for i in data]\n",
    "            else:\n",
    "                data = json.load(f)\n",
    "    # if split == \"train\":\n",
    "    #     data = extract_single_dict(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'ACE'\n",
    "root = './data_incremental'\n",
    "split = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [instance for t in collect_from_json(dataset, root, split)[1] for instance in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def get_one_hot_true_label_and_true_trigger(data_instance, num_label):\n",
    "    true_label = []\n",
    "    trigger_word = []\n",
    "    seq_len = len(data_instance[\"piece_ids\"]) + 1 # because start_index of piece_ids is 1 instead of 0\n",
    "    for i in range(len(data_instance[\"label\"])):\n",
    "        if data_instance[\"label\"][i] != 0:\n",
    "            true_label.append(data_instance[\"label\"][i])\n",
    "            trigger_word.append(data_instance[\"span\"][i])\n",
    "\n",
    "    set_label_in_one_sentence = set(true_label)\n",
    "    true_one_hot_trigger_vector = torch.zeros(num_label)\n",
    "    for i in set_label_in_one_sentence:\n",
    "        true_one_hot_trigger_vector += torch.eye(num_label)[i]\n",
    "\n",
    "    true_one_hot_label_vector = torch.zeros(seq_len)\n",
    "    trigger = []\n",
    "    for i in trigger_word:\n",
    "        trigger.extend(i)\n",
    "\n",
    "    set_trig = set(trigger)\n",
    "    for i in set_trig:\n",
    "        true_one_hot_label_vector += torch.eye(seq_len)[i]\n",
    "    return true_one_hot_trigger_vector, true_one_hot_label_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = get_one_hot_true_label_and_true_trigger(data[0],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "47\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "print(len(data[0]['piece_ids']))\n",
    "print(len(data[0]['label']))\n",
    "print(len(data[0]['span']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for instance in data:\n",
    "    true_one_hot_trigger_vector, true_one_hot_label_vector = get_one_hot_true_label_and_true_trigger(instance, 10)\n",
    "    instance['true_one_hot_trigger_vector'] = true_one_hot_trigger_vector.tolist()\n",
    "    instance['true_one_hot_label_vector'] = true_one_hot_label_vector.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'piece_ids': [101,\n",
       "  3960,\n",
       "  1010,\n",
       "  1045,\n",
       "  2228,\n",
       "  2008,\n",
       "  1996,\n",
       "  3114,\n",
       "  7955,\n",
       "  1999,\n",
       "  1996,\n",
       "  2148,\n",
       "  1011,\n",
       "  1011,\n",
       "  2017,\n",
       "  2113,\n",
       "  1010,\n",
       "  2034,\n",
       "  1997,\n",
       "  2035,\n",
       "  1010,\n",
       "  2057,\n",
       "  2020,\n",
       "  1011,\n",
       "  1011,\n",
       "  2043,\n",
       "  5951,\n",
       "  8573,\n",
       "  2001,\n",
       "  2700,\n",
       "  2343,\n",
       "  1010,\n",
       "  2057,\n",
       "  2018,\n",
       "  2042,\n",
       "  2542,\n",
       "  2054,\n",
       "  2057,\n",
       "  2245,\n",
       "  2001,\n",
       "  2145,\n",
       "  1037,\n",
       "  11438,\n",
       "  3842,\n",
       "  2044,\n",
       "  1996,\n",
       "  2942,\n",
       "  2162,\n",
       "  1012,\n",
       "  102],\n",
       " 'label': [6,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'span': [[29, 29],\n",
       "  [46, 47],\n",
       "  [1, 1],\n",
       "  [2, 2],\n",
       "  [3, 3],\n",
       "  [4, 4],\n",
       "  [5, 5],\n",
       "  [6, 6],\n",
       "  [7, 7],\n",
       "  [8, 8],\n",
       "  [9, 9],\n",
       "  [10, 10],\n",
       "  [11, 11],\n",
       "  [12, 12],\n",
       "  [13, 13],\n",
       "  [14, 14],\n",
       "  [15, 15],\n",
       "  [16, 16],\n",
       "  [17, 17],\n",
       "  [18, 18],\n",
       "  [19, 19],\n",
       "  [20, 20],\n",
       "  [21, 21],\n",
       "  [22, 22],\n",
       "  [23, 23],\n",
       "  [24, 24],\n",
       "  [25, 25],\n",
       "  [26, 26],\n",
       "  [27, 27],\n",
       "  [28, 28],\n",
       "  [30, 30],\n",
       "  [31, 31],\n",
       "  [32, 32],\n",
       "  [33, 33],\n",
       "  [34, 34],\n",
       "  [35, 35],\n",
       "  [36, 36],\n",
       "  [37, 37],\n",
       "  [38, 38],\n",
       "  [39, 39],\n",
       "  [40, 40],\n",
       "  [41, 41],\n",
       "  [42, 42],\n",
       "  [43, 43],\n",
       "  [44, 44],\n",
       "  [45, 45],\n",
       "  [48, 48]],\n",
       " 'true_one_hot_trigger_vector': [0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'true_one_hot_label_vector': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def get_one_hot_true_label_and_true_trigger(data_instance, num_label):\n",
    "    true_label = []\n",
    "    true_trigger = []\n",
    "    seq_len = len(data_instance[\"piece_ids\"]) # because start_index of piece_ids is 1 instead of 0\n",
    "    \n",
    "    for i in range(len(data_instance[\"label\"])):\n",
    "        if data_instance[\"label\"][i] != 0:\n",
    "            true_label.append(data_instance[\"label\"][i])\n",
    "            true_trigger.append(data_instance[\"span\"][i])\n",
    "\n",
    "\n",
    "    true_one_hot_label_vector = torch.zeros(num_label)\n",
    "    true_one_hot_trigger_vector = torch.zeros(seq_len)\n",
    "\n",
    "    set_label_in_one_sentence = set([label.item() for label in true_label])\n",
    "    for i in set_label_in_one_sentence:\n",
    "        true_one_hot_label_vector += torch.eye(num_label)[i]\n",
    "\n",
    "\n",
    "    list_trigger = [trigger.tolist() for trigger in true_trigger]\n",
    "    trigger = []\n",
    "    for i in list_trigger:\n",
    "        trigger.extend(i)\n",
    "\n",
    "    set_trig_in_one_sentence = set(trigger)\n",
    "\n",
    "    for i in set_trig_in_one_sentence:\n",
    "        true_one_hot_trigger_vector += torch.eye(seq_len)[i]\n",
    "    \n",
    "    return true_one_hot_trigger_vector, true_one_hot_label_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "def true_label_and_trigger(train_x,train_y,train_masks, train_span, class_num):\n",
    "    num_instance = len(train_x)\n",
    "    true_one_hot_label_vectors = []\n",
    "    true_one_hot_trigger_vectors = []\n",
    "    for i in range(num_instance):\n",
    "        data_instace={\n",
    "            'piece_ids': train_x[i],\n",
    "            'label': train_y[i],\n",
    "            'span': train_span[i],\n",
    "            'mask': train_masks[i]\n",
    "        }\n",
    "\n",
    "        true_one_hot_trigger_vector, true_one_hot_label_vector = get_one_hot_true_label_and_true_trigger(data_instance=data_instace,num_label=class_num)\n",
    "        true_one_hot_trigger_vectors.append(true_one_hot_trigger_vector)\n",
    "        true_one_hot_label_vectors.append(true_one_hot_label_vector)\n",
    "    return true_one_hot_trigger_vectors, true_one_hot_label_vectors\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = torch.tensor([[  101,  6398,  1024,  6175,  2003,  2025,  1996,  2069,  2510,  2564,\n",
    "          2040,  2363,  1037,  6302,  1998,  3661,  1012,   102,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0],\n",
    "        [  101, 21524,  1998,  2037,  2079, 24968,  5611,  6956, 19974,  2224,\n",
    "          1996,  2773,  1036,  1036,  6139,  1005,  1005,  2043,  9694,  2008,\n",
    "          3956,  2681,  1996,  2225,  2924,  1998, 14474,  1998,  4487, 11512,\n",
    "          9286,  3644,  7617,  1012,   102,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0],\n",
    "        [  101,  1045,  2079,  1050,  1005,  1056,  2228,  2008,  1005,  1055,\n",
    "          3243,  8321,  2004,  2000,  2054,  2002,  2626,  2033,  2055,  1012,\n",
    "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0],\n",
    "        [  101,  2358, 23111,  6582,  1010,  2040,  2001,  2809,  2706,  6875,\n",
    "          1010,  2018,  3041,  2042,  3331,  2007,  2014,  2388,  2006,  1996,\n",
    "          3042,  1010,  1998,  5112,  2039,  3038,  1037,  2450,  2016,  2018,\n",
    "         11834,  3064,  2007,  3784,  2018,  2074,  3369,  2012,  2014,  2341,\n",
    "          1010,  4614,  2056,  1012,   102,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0]])\n",
    "\n",
    "train_y = [torch.tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), torch.tensor([2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0, 0, 0, 0, 0]), torch.tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), torch.tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]\n",
    "train_masks = torch.tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0]])\n",
    "train_span = [torch.tensor([[15, 15],\n",
    "        [ 1,  1],\n",
    "        [ 2,  2],\n",
    "        [ 3,  3],\n",
    "        [ 4,  4],\n",
    "        [ 5,  5],\n",
    "        [ 6,  6],\n",
    "        [ 7,  7],\n",
    "        [ 8,  8],\n",
    "        [ 9,  9],\n",
    "        [10, 10],\n",
    "        [11, 11],\n",
    "        [12, 12],\n",
    "        [13, 13],\n",
    "        [14, 14],\n",
    "        [16, 16]]), torch.tensor([[21, 21],\n",
    "        [ 1,  1],\n",
    "        [ 2,  2],\n",
    "        [ 3,  3],\n",
    "        [ 4,  4],\n",
    "        [ 5,  5],\n",
    "        [ 6,  6],\n",
    "        [ 7,  7],\n",
    "        [ 8,  8],\n",
    "        [ 9,  9],\n",
    "        [10, 10],\n",
    "        [11, 11],\n",
    "        [12, 12],\n",
    "        [13, 13],\n",
    "        [14, 14],\n",
    "        [15, 15],\n",
    "        [16, 16],\n",
    "        [17, 17],\n",
    "        [18, 18],\n",
    "        [19, 19],\n",
    "        [20, 20],\n",
    "        [22, 22],\n",
    "        [23, 23],\n",
    "        [24, 24],\n",
    "        [25, 25],\n",
    "        [26, 26],\n",
    "        [27, 27],\n",
    "        [28, 28],\n",
    "        [29, 29],\n",
    "        [30, 30],\n",
    "        [31, 31],\n",
    "        [32, 32],\n",
    "        [33, 33]]), torch.tensor([[16, 16],\n",
    "        [ 1,  1],\n",
    "        [ 2,  2],\n",
    "        [ 3,  3],\n",
    "        [ 4,  4],\n",
    "        [ 5,  5],\n",
    "        [ 6,  6],\n",
    "        [ 7,  7],\n",
    "        [ 8,  8],\n",
    "        [ 9,  9],\n",
    "        [10, 10],\n",
    "        [11, 11],\n",
    "        [12, 12],\n",
    "        [13, 13],\n",
    "        [14, 14],\n",
    "        [15, 15],\n",
    "        [17, 17],\n",
    "        [18, 18],\n",
    "        [19, 19]]), torch.tensor([[20, 20],\n",
    "        [30, 31],\n",
    "        [ 1,  1],\n",
    "        [ 2,  2],\n",
    "        [ 3,  3],\n",
    "        [ 4,  4],\n",
    "        [ 5,  5],\n",
    "        [ 6,  6],\n",
    "        [ 7,  7],\n",
    "        [ 8,  8],\n",
    "        [ 9,  9],\n",
    "        [10, 10],\n",
    "        [11, 11],\n",
    "        [12, 12],\n",
    "        [13, 13],\n",
    "        [14, 14],\n",
    "        [15, 15],\n",
    "        [16, 16],\n",
    "        [17, 17],\n",
    "        [18, 18],\n",
    "        [19, 19],\n",
    "        [21, 21],\n",
    "        [22, 22],\n",
    "        [23, 23],\n",
    "        [24, 24],\n",
    "        [25, 25],\n",
    "        [26, 26],\n",
    "        [27, 27],\n",
    "        [28, 28],\n",
    "        [29, 29],\n",
    "        [32, 32],\n",
    "        [33, 33],\n",
    "        [34, 34],\n",
    "        [35, 35],\n",
    "        [36, 36],\n",
    "        [37, 37],\n",
    "        [38, 38],\n",
    "        [39, 39],\n",
    "        [40, 40],\n",
    "        [41, 41],\n",
    "        [42, 42],\n",
    "        [43, 43]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_trigger, true_label = true_label_and_trigger(train_x=train_x,train_y=train_y,train_masks=train_masks,train_span=train_span,class_num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_instance = {\n",
    "    \"piece_ids\": train_x[3],\n",
    "    \"label\": train_y[3],\n",
    "    \"span\": train_span[3],\n",
    "    \"mask\": train_masks[3],\n",
    "}\n",
    "a, b = get_one_hot_true_label_and_true_trigger(data_instance=data_instance,num_label=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[192], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# sample ---------------\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[  \u001b[38;5;241m101\u001b[39m,  \u001b[38;5;241m2057\u001b[39m,  \u001b[38;5;241m3191\u001b[39m,  \u001b[38;5;241m2035\u001b[39m,  \u001b[38;5;241m1997\u001b[39m,  \u001b[38;5;241m2115\u001b[39m,  \u001b[38;5;241m1041\u001b[39m,  \u001b[38;5;241m1011\u001b[39m,  \u001b[38;5;241m5653\u001b[39m,  \u001b[38;5;241m1012\u001b[39m,\n\u001b[1;32m      3\u001b[0m            \u001b[38;5;241m102\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m      4\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m      5\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m      6\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m      7\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m      8\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m      9\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     10\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     11\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     12\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     13\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     14\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     15\u001b[0m         [  \u001b[38;5;241m101\u001b[39m,  \u001b[38;5;241m2004\u001b[39m,  \u001b[38;5;241m1057\u001b[39m,  \u001b[38;5;241m1012\u001b[39m,  \u001b[38;5;241m1055\u001b[39m,  \u001b[38;5;241m1012\u001b[39m,  \u001b[38;5;241m7753\u001b[39m,  \u001b[38;5;241m2333\u001b[39m,  \u001b[38;5;241m4794\u001b[39m,  \u001b[38;5;241m2247\u001b[39m,\n\u001b[1;32m     16\u001b[0m           \u001b[38;5;241m1996\u001b[39m, \u001b[38;5;241m14841\u001b[39m, \u001b[38;5;241m16523\u001b[39m,  \u001b[38;5;241m2483\u001b[39m,  \u001b[38;5;241m2314\u001b[39m,  \u001b[38;5;241m1010\u001b[39m,  \u001b[38;5;241m8956\u001b[39m,  \u001b[38;5;241m2015\u001b[39m,  \u001b[38;5;241m6783\u001b[39m,  \u001b[38;5;241m2247\u001b[39m,\n\u001b[1;32m     17\u001b[0m           \u001b[38;5;241m2049\u001b[39m,  \u001b[38;5;241m5085\u001b[39m,  \u001b[38;5;241m1998\u001b[39m,  \u001b[38;5;241m2070\u001b[39m,  \u001b[38;5;241m5598\u001b[39m,  \u001b[38;5;241m1999\u001b[39m,  \u001b[38;5;241m1996\u001b[39m,  \u001b[38;5;241m2300\u001b[39m,  \u001b[38;5;241m1012\u001b[39m,   \u001b[38;5;241m102\u001b[39m,\n\u001b[1;32m     18\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     19\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     20\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     21\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     22\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     23\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     24\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     25\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     26\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     27\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     28\u001b[0m         [  \u001b[38;5;241m101\u001b[39m,  \u001b[38;5;241m3398\u001b[39m,  \u001b[38;5;241m1010\u001b[39m,  \u001b[38;5;241m1998\u001b[39m,  \u001b[38;5;241m2027\u001b[39m,  \u001b[38;5;241m1039\u001b[39m,  \u001b[38;5;241m1011\u001b[39m,  \u001b[38;5;241m1996\u001b[39m,  \u001b[38;5;241m2272\u001b[39m,  \u001b[38;5;241m2188\u001b[39m,\n\u001b[1;32m     29\u001b[0m           \u001b[38;5;241m2000\u001b[39m,  \u001b[38;5;241m2498\u001b[39m,  \u001b[38;5;241m2044\u001b[39m,  \u001b[38;5;241m1043\u001b[39m,  \u001b[38;5;241m1011\u001b[39m,  \u001b[38;5;241m2035\u001b[39m,  \u001b[38;5;241m2027\u001b[39m,  \u001b[38;5;241m1005\u001b[39m,  \u001b[38;5;241m2310\u001b[39m,  \u001b[38;5;241m2908\u001b[39m,\n\u001b[1;32m     30\u001b[0m           \u001b[38;5;241m2083\u001b[39m,  \u001b[38;5;241m2027\u001b[39m,  \u001b[38;5;241m2272\u001b[39m,  \u001b[38;5;241m2188\u001b[39m,  \u001b[38;5;241m1998\u001b[39m,  \u001b[38;5;241m2027\u001b[39m,  \u001b[38;5;241m2031\u001b[39m,  \u001b[38;5;241m2498\u001b[39m,  \u001b[38;5;241m1012\u001b[39m,   \u001b[38;5;241m102\u001b[39m,\n\u001b[1;32m     31\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     32\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     33\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     34\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     35\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     36\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     37\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     38\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     39\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     40\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     41\u001b[0m         [  \u001b[38;5;241m101\u001b[39m,  \u001b[38;5;241m2005\u001b[39m,  \u001b[38;5;241m1996\u001b[39m,  \u001b[38;5;241m2279\u001b[39m,  \u001b[38;5;241m2260\u001b[39m,  \u001b[38;5;241m2847\u001b[39m,  \u001b[38;5;241m2046\u001b[39m,  \u001b[38;5;241m1996\u001b[39m,  \u001b[38;5;241m2851\u001b[39m,  \u001b[38;5;241m1010\u001b[39m,\n\u001b[1;32m     42\u001b[0m           \u001b[38;5;241m9738\u001b[39m,  \u001b[38;5;241m2013\u001b[39m,  \u001b[38;5;241m1996\u001b[39m,  \u001b[38;5;241m6839\u001b[39m,  \u001b[38;5;241m2097\u001b[39m,  \u001b[38;5;241m4875\u001b[39m,  \u001b[38;5;241m6416\u001b[39m,  \u001b[38;5;241m2058\u001b[39m,  \u001b[38;5;241m7041\u001b[39m,  \u001b[38;5;241m1012\u001b[39m,\n\u001b[1;32m     43\u001b[0m            \u001b[38;5;241m102\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     44\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     45\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     46\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     47\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     48\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     49\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     50\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     51\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     52\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     53\u001b[0m              \u001b[38;5;241m0\u001b[39m,     \u001b[38;5;241m0\u001b[39m]], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     54\u001b[0m y_sample \u001b[38;5;241m=\u001b[39m [torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m), torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m), torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     56\u001b[0m         \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m), torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m     57\u001b[0m        device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)]\n\u001b[1;32m     58\u001b[0m masks_sample \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([[\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     59\u001b[0m          \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     60\u001b[0m          \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     80\u001b[0m          \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m     81\u001b[0m          \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m]], device\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/natmin/lib/python3.11/site-packages/torch/cuda/__init__.py:305\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    300\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    301\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    302\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    303\u001b[0m     )\n\u001b[1;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    306\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    307\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    309\u001b[0m     )\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "# sample ---------------\n",
    "x = torch.tensor([[  101,  2057,  3191,  2035,  1997,  2115,  1041,  1011,  5653,  1012,\n",
    "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0],\n",
    "        [  101,  2004,  1057,  1012,  1055,  1012,  7753,  2333,  4794,  2247,\n",
    "          1996, 14841, 16523,  2483,  2314,  1010,  8956,  2015,  6783,  2247,\n",
    "          2049,  5085,  1998,  2070,  5598,  1999,  1996,  2300,  1012,   102,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0],\n",
    "        [  101,  3398,  1010,  1998,  2027,  1039,  1011,  1996,  2272,  2188,\n",
    "          2000,  2498,  2044,  1043,  1011,  2035,  2027,  1005,  2310,  2908,\n",
    "          2083,  2027,  2272,  2188,  1998,  2027,  2031,  2498,  1012,   102,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0],\n",
    "        [  101,  2005,  1996,  2279,  2260,  2847,  2046,  1996,  2851,  1010,\n",
    "          9738,  2013,  1996,  6839,  2097,  4875,  6416,  2058,  7041,  1012,\n",
    "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0]], device='cuda:0')\n",
    "y_sample = [torch.tensor([1, 0, 0, 0, 0, 0, 0, 0], device='cuda:0'), torch.tensor([2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0], device='cuda:0'), torch.tensor([2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0], device='cuda:0'), torch.tensor([2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
    "       device='cuda:0')]\n",
    "masks_sample = torch.tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0]], device='cuda:0')\n",
    "span_sample = [torch.tensor([[6, 8],\n",
    "        [1, 1],\n",
    "        [2, 2],\n",
    "        [3, 3],\n",
    "        [4, 4],\n",
    "        [5, 5],\n",
    "        [7, 7],\n",
    "        [9, 9]], device='cuda:0'), torch.tensor([[ 7,  7],\n",
    "        [18, 18],\n",
    "        [ 1,  1],\n",
    "        [ 2,  2],\n",
    "        [ 3,  3],\n",
    "        [ 4,  4],\n",
    "        [ 5,  5],\n",
    "        [ 6,  6],\n",
    "        [ 8,  8],\n",
    "        [ 9,  9],\n",
    "        [10, 10],\n",
    "        [11, 11],\n",
    "        [12, 12],\n",
    "        [13, 13],\n",
    "        [14, 14],\n",
    "        [15, 15],\n",
    "        [16, 16],\n",
    "        [17, 17],\n",
    "        [19, 19],\n",
    "        [20, 20],\n",
    "        [21, 21],\n",
    "        [22, 22],\n",
    "        [23, 23],\n",
    "        [24, 24],\n",
    "        [25, 25],\n",
    "        [26, 26],\n",
    "        [27, 27],\n",
    "        [28, 28]], device='cuda:0'), torch.tensor([[ 8,  8],\n",
    "        [22, 22],\n",
    "        [ 1,  1],\n",
    "        [ 2,  2],\n",
    "        [ 3,  3],\n",
    "        [ 4,  4],\n",
    "        [ 5,  5],\n",
    "        [ 6,  6],\n",
    "        [ 7,  7],\n",
    "        [ 9,  9],\n",
    "        [10, 10],\n",
    "        [11, 11],\n",
    "        [12, 12],\n",
    "        [13, 13],\n",
    "        [14, 14],\n",
    "        [15, 15],\n",
    "        [16, 16],\n",
    "        [17, 17],\n",
    "        [18, 18],\n",
    "        [19, 19],\n",
    "        [20, 20],\n",
    "        [21, 21],\n",
    "        [23, 23],\n",
    "        [24, 24],\n",
    "        [25, 25],\n",
    "        [26, 26],\n",
    "        [27, 27],\n",
    "        [28, 28]], device='cuda:0'), torch.tensor([[15, 15],\n",
    "        [ 1,  1],\n",
    "        [ 2,  2],\n",
    "        [ 3,  3],\n",
    "        [ 4,  4],\n",
    "        [ 5,  5],\n",
    "        [ 6,  6],\n",
    "        [ 7,  7],\n",
    "        [ 8,  8],\n",
    "        [ 9,  9],\n",
    "        [10, 10],\n",
    "        [11, 11],\n",
    "        [12, 12],\n",
    "        [13, 13],\n",
    "        [14, 14],\n",
    "        [16, 16],\n",
    "        [17, 17],\n",
    "        [18, 18],\n",
    "        [19, 19]], device='cuda:0')]\n",
    "# true_trig and true_label\n",
    "true_trig_sample = [torch.tensor([0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), torch.tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), torch.tensor([0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), torch.tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
    "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])]\n",
    "true_label_sample = [torch.tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]), torch.tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), torch.tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]), torch.tensor([0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])]\n",
    "# end--------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "natmin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
