{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "args_perm_id = 0\n",
    "args_task_num = 5\n",
    "args_class_num = 10\n",
    "args_shot_num = 5\n",
    "def collect_from_json(dataset, root, split):\n",
    "    if split == \"train\":\n",
    "        pth = os.path.join(\n",
    "            root,\n",
    "            dataset,\n",
    "            \"perm\" + str(args_perm_id),\n",
    "            f\"{dataset}_{args_task_num}task_{args_class_num // args_task_num}way_{args_shot_num}shot.{split}.jsonl\",\n",
    "        )\n",
    "    elif split in [\"dev\", \"test\"]:\n",
    "        pth = os.path.join(root, dataset, f\"{dataset}.{split}.jsonl\")\n",
    "    elif split == \"stream\":\n",
    "        pth = os.path.join(\n",
    "            root,\n",
    "            dataset,\n",
    "            f\"stream_label_{args_task_num}task_{args_class_num // args_task_num}way.json\",\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f'Split \"{split}\" value wrong!')\n",
    "    if not os.path.exists(pth):\n",
    "        raise FileNotFoundError(f\"Path {pth} do not exist!\")\n",
    "    else:\n",
    "        with open(pth) as f:\n",
    "            if pth.endswith(\".jsonl\"):\n",
    "                data = [json.loads(line) for line in f]\n",
    "                if split == \"train\":\n",
    "                    data = [list(i.values()) for i in data]\n",
    "            else:\n",
    "                data = json.load(f)\n",
    "    # if split == \"train\":\n",
    "    #     data = extract_single_dict(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'ACE'\n",
    "root = './data_incremental'\n",
    "split = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [instance for t in collect_from_json(dataset, root, split)[1] for instance in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def get_one_hot_true_label_and_true_trigger(data_instance, num_label):\n",
    "    true_label = []\n",
    "    trigger_word = []\n",
    "    seq_len = len(data_instance[\"piece_ids\"]) + 1 # because start_index of piece_ids is 1 instead of 0\n",
    "    for i in range(len(data_instance[\"label\"])):\n",
    "        if data_instance[\"label\"][i] != 0:\n",
    "            true_label.append(data_instance[\"label\"][i])\n",
    "            trigger_word.append(data_instance[\"span\"][i])\n",
    "\n",
    "    set_label_in_one_sentence = set(true_label)\n",
    "    true_one_hot_trigger_vector = torch.zeros(num_label)\n",
    "    for i in set_label_in_one_sentence:\n",
    "        true_one_hot_trigger_vector += torch.eye(num_label)[i]\n",
    "\n",
    "    true_one_hot_label_vector = torch.zeros(seq_len)\n",
    "    trigger = []\n",
    "    for i in trigger_word:\n",
    "        trigger.extend(i)\n",
    "\n",
    "    set_trig = set(trigger)\n",
    "    for i in set_trig:\n",
    "        true_one_hot_label_vector += torch.eye(seq_len)[i]\n",
    "    return true_one_hot_trigger_vector, true_one_hot_label_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = get_one_hot_true_label_and_true_trigger(data[0],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "47\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "print(len(data[0]['piece_ids']))\n",
    "print(len(data[0]['label']))\n",
    "print(len(data[0]['span']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for instance in data:\n",
    "    true_one_hot_trigger_vector, true_one_hot_label_vector = get_one_hot_true_label_and_true_trigger(instance, 10)\n",
    "    instance['true_one_hot_trigger_vector'] = true_one_hot_trigger_vector.tolist()\n",
    "    instance['true_one_hot_label_vector'] = true_one_hot_label_vector.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'piece_ids': [101,\n",
       "  3960,\n",
       "  1010,\n",
       "  1045,\n",
       "  2228,\n",
       "  2008,\n",
       "  1996,\n",
       "  3114,\n",
       "  7955,\n",
       "  1999,\n",
       "  1996,\n",
       "  2148,\n",
       "  1011,\n",
       "  1011,\n",
       "  2017,\n",
       "  2113,\n",
       "  1010,\n",
       "  2034,\n",
       "  1997,\n",
       "  2035,\n",
       "  1010,\n",
       "  2057,\n",
       "  2020,\n",
       "  1011,\n",
       "  1011,\n",
       "  2043,\n",
       "  5951,\n",
       "  8573,\n",
       "  2001,\n",
       "  2700,\n",
       "  2343,\n",
       "  1010,\n",
       "  2057,\n",
       "  2018,\n",
       "  2042,\n",
       "  2542,\n",
       "  2054,\n",
       "  2057,\n",
       "  2245,\n",
       "  2001,\n",
       "  2145,\n",
       "  1037,\n",
       "  11438,\n",
       "  3842,\n",
       "  2044,\n",
       "  1996,\n",
       "  2942,\n",
       "  2162,\n",
       "  1012,\n",
       "  102],\n",
       " 'label': [6,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'span': [[29, 29],\n",
       "  [46, 47],\n",
       "  [1, 1],\n",
       "  [2, 2],\n",
       "  [3, 3],\n",
       "  [4, 4],\n",
       "  [5, 5],\n",
       "  [6, 6],\n",
       "  [7, 7],\n",
       "  [8, 8],\n",
       "  [9, 9],\n",
       "  [10, 10],\n",
       "  [11, 11],\n",
       "  [12, 12],\n",
       "  [13, 13],\n",
       "  [14, 14],\n",
       "  [15, 15],\n",
       "  [16, 16],\n",
       "  [17, 17],\n",
       "  [18, 18],\n",
       "  [19, 19],\n",
       "  [20, 20],\n",
       "  [21, 21],\n",
       "  [22, 22],\n",
       "  [23, 23],\n",
       "  [24, 24],\n",
       "  [25, 25],\n",
       "  [26, 26],\n",
       "  [27, 27],\n",
       "  [28, 28],\n",
       "  [30, 30],\n",
       "  [31, 31],\n",
       "  [32, 32],\n",
       "  [33, 33],\n",
       "  [34, 34],\n",
       "  [35, 35],\n",
       "  [36, 36],\n",
       "  [37, 37],\n",
       "  [38, 38],\n",
       "  [39, 39],\n",
       "  [40, 40],\n",
       "  [41, 41],\n",
       "  [42, 42],\n",
       "  [43, 43],\n",
       "  [44, 44],\n",
       "  [45, 45],\n",
       "  [48, 48]],\n",
       " 'true_one_hot_trigger_vector': [0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'true_one_hot_label_vector': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def get_one_hot_true_label_and_true_trigger(data_instance, num_label):\n",
    "    true_label = []\n",
    "    true_trigger = []\n",
    "    seq_len = len(data_instance[\"piece_ids\"]) # because start_index of piece_ids is 1 instead of 0\n",
    "    \n",
    "    for i in range(len(data_instance[\"label\"])):\n",
    "        if data_instance[\"label\"][i] != 0:\n",
    "            true_label.append(data_instance[\"label\"][i])\n",
    "            true_trigger.append(data_instance[\"span\"][i])\n",
    "\n",
    "\n",
    "    true_one_hot_label_vector = torch.zeros(num_label)\n",
    "    true_one_hot_trigger_vector = torch.zeros(seq_len)\n",
    "\n",
    "    set_label_in_one_sentence = set([label.item() for label in true_label])\n",
    "    for i in set_label_in_one_sentence:\n",
    "        true_one_hot_label_vector += torch.eye(num_label)[i]\n",
    "\n",
    "\n",
    "    list_trigger = [trigger.tolist() for trigger in true_trigger]\n",
    "    trigger = []\n",
    "    for i in list_trigger:\n",
    "        trigger.extend(i)\n",
    "\n",
    "    set_trig_in_one_sentence = set(trigger)\n",
    "\n",
    "    for i in set_trig_in_one_sentence:\n",
    "        true_one_hot_trigger_vector += torch.eye(seq_len)[i]\n",
    "    \n",
    "    return true_one_hot_trigger_vector, true_one_hot_label_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "def get_one_hot_true_label_and_true_trigger(data_instance, num_label):\n",
    "    true_label = []\n",
    "    true_trigger = []\n",
    "    seq_len = len(data_instance[\"piece_ids\"]) # because start_index of piece_ids is 1 instead of 0\n",
    "    matrix_word_is_label = torch.zeros(seq_len, num_label,dtype=int)\n",
    "    for i in range(len(data_instance[\"label\"])):\n",
    "        if data_instance[\"label\"][i] != 0:\n",
    "            true_label.append(data_instance[\"label\"][i])\n",
    "            true_trigger.append(data_instance[\"span\"][i])\n",
    "            for word_is_trigger in data_instance['span'][i]:\n",
    "                matrix_word_is_label[word_is_trigger,data_instance['label'][i]] = 1\n",
    "\n",
    "\n",
    "    true_one_hot_label_vector = torch.zeros(num_label)\n",
    "    true_one_hot_trigger_vector = torch.zeros(seq_len)\n",
    "\n",
    "    set_label_in_one_sentence = set([label.item() for label in true_label])\n",
    "    for i in set_label_in_one_sentence:\n",
    "        true_one_hot_label_vector += torch.eye(num_label)[i]\n",
    "\n",
    "\n",
    "    list_trigger = [trigger.tolist() for trigger in true_trigger]\n",
    "    trigger = []\n",
    "    for i in list_trigger:\n",
    "        trigger.extend(i)\n",
    "\n",
    "    set_trig_in_one_sentence = set(trigger)\n",
    "\n",
    "    for i in set_trig_in_one_sentence:\n",
    "        true_one_hot_trigger_vector += torch.eye(seq_len)[i]\n",
    "    true_one_hot_trigger_vector = true_one_hot_trigger_vector.to(device)\n",
    "    true_one_hot_label_vector = true_one_hot_label_vector.to(device)\n",
    "    matrix_word_is_label = matrix_word_is_label.to(device)\n",
    "    return true_one_hot_trigger_vector, true_one_hot_label_vector, matrix_word_is_label\n",
    "\n",
    "def true_label_and_trigger(train_x,train_y,train_masks, train_span, class_num):\n",
    "    num_instance = len(train_x)\n",
    "    true_one_hot_label_vectors = []\n",
    "    true_one_hot_trigger_vectors = []\n",
    "    golden_matrix = []\n",
    "    for i in range(num_instance):\n",
    "        data_instace={\n",
    "            'piece_ids': train_x[i],\n",
    "            'label': train_y[i],\n",
    "            'span': train_span[i],\n",
    "            'mask': train_masks[i]\n",
    "        }\n",
    "\n",
    "        true_one_hot_trigger_vector, true_one_hot_label_vector, matrix_word_is_label= get_one_hot_true_label_and_true_trigger(data_instance=data_instace,num_label=class_num)\n",
    "        true_one_hot_trigger_vectors.append(true_one_hot_trigger_vector)\n",
    "        true_one_hot_label_vectors.append(true_one_hot_label_vector)\n",
    "        golden_matrix.append(matrix_word_is_label)\n",
    "    true_one_hot_trigger_vectors = torch.stack([x.to(device) for x in true_one_hot_trigger_vectors])\n",
    "    true_one_hot_label_vectors = torch.stack([x.to(device) for x in true_one_hot_label_vectors])\n",
    "    pi_golden_matrix = torch.stack([x.to(device) for x in golden_matrix])\n",
    "    return true_one_hot_trigger_vectors, true_one_hot_label_vectors, pi_golden_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "train_x = torch.tensor([[  101,  6398,  1024,  6175,  2003,  2025,  1996,  2069,  2510,  2564,\n",
    "          2040,  2363,  1037,  6302,  1998,  3661,  1012,   102,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0],\n",
    "        [  101, 21524,  1998,  2037,  2079, 24968,  5611,  6956, 19974,  2224,\n",
    "          1996,  2773,  1036,  1036,  6139,  1005,  1005,  2043,  9694,  2008,\n",
    "          3956,  2681,  1996,  2225,  2924,  1998, 14474,  1998,  4487, 11512,\n",
    "          9286,  3644,  7617,  1012,   102,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0],\n",
    "        [  101,  1045,  2079,  1050,  1005,  1056,  2228,  2008,  1005,  1055,\n",
    "          3243,  8321,  2004,  2000,  2054,  2002,  2626,  2033,  2055,  1012,\n",
    "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0],\n",
    "        [  101,  2358, 23111,  6582,  1010,  2040,  2001,  2809,  2706,  6875,\n",
    "          1010,  2018,  3041,  2042,  3331,  2007,  2014,  2388,  2006,  1996,\n",
    "          3042,  1010,  1998,  5112,  2039,  3038,  1037,  2450,  2016,  2018,\n",
    "         11834,  3064,  2007,  3784,  2018,  2074,  3369,  2012,  2014,  2341,\n",
    "          1010,  4614,  2056,  1012,   102,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0]])\n",
    "\n",
    "train_y = [torch.tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), torch.tensor([2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0, 0, 0, 0, 0]), torch.tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), torch.tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]\n",
    "train_masks = torch.tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0]])\n",
    "train_span = [torch.tensor([[15, 15],\n",
    "        [ 1,  1],\n",
    "        [ 2,  2],\n",
    "        [ 3,  3],\n",
    "        [ 4,  4],\n",
    "        [ 5,  5],\n",
    "        [ 6,  6],\n",
    "        [ 7,  7],\n",
    "        [ 8,  8],\n",
    "        [ 9,  9],\n",
    "        [10, 10],\n",
    "        [11, 11],\n",
    "        [12, 12],\n",
    "        [13, 13],\n",
    "        [14, 14],\n",
    "        [16, 16]]), torch.tensor([[21, 21],\n",
    "        [ 1,  1],\n",
    "        [ 2,  2],\n",
    "        [ 3,  3],\n",
    "        [ 4,  4],\n",
    "        [ 5,  5],\n",
    "        [ 6,  6],\n",
    "        [ 7,  7],\n",
    "        [ 8,  8],\n",
    "        [ 9,  9],\n",
    "        [10, 10],\n",
    "        [11, 11],\n",
    "        [12, 12],\n",
    "        [13, 13],\n",
    "        [14, 14],\n",
    "        [15, 15],\n",
    "        [16, 16],\n",
    "        [17, 17],\n",
    "        [18, 18],\n",
    "        [19, 19],\n",
    "        [20, 20],\n",
    "        [22, 22],\n",
    "        [23, 23],\n",
    "        [24, 24],\n",
    "        [25, 25],\n",
    "        [26, 26],\n",
    "        [27, 27],\n",
    "        [28, 28],\n",
    "        [29, 29],\n",
    "        [30, 30],\n",
    "        [31, 31],\n",
    "        [32, 32],\n",
    "        [33, 33]]), torch.tensor([[16, 16],\n",
    "        [ 1,  1],\n",
    "        [ 2,  2],\n",
    "        [ 3,  3],\n",
    "        [ 4,  4],\n",
    "        [ 5,  5],\n",
    "        [ 6,  6],\n",
    "        [ 7,  7],\n",
    "        [ 8,  8],\n",
    "        [ 9,  9],\n",
    "        [10, 10],\n",
    "        [11, 11],\n",
    "        [12, 12],\n",
    "        [13, 13],\n",
    "        [14, 14],\n",
    "        [15, 15],\n",
    "        [17, 17],\n",
    "        [18, 18],\n",
    "        [19, 19]]), torch.tensor([[20, 20],\n",
    "        [30, 31],\n",
    "        [ 1,  1],\n",
    "        [ 2,  2],\n",
    "        [ 3,  3],\n",
    "        [ 4,  4],\n",
    "        [ 5,  5],\n",
    "        [ 6,  6],\n",
    "        [ 7,  7],\n",
    "        [ 8,  8],\n",
    "        [ 9,  9],\n",
    "        [10, 10],\n",
    "        [11, 11],\n",
    "        [12, 12],\n",
    "        [13, 13],\n",
    "        [14, 14],\n",
    "        [15, 15],\n",
    "        [16, 16],\n",
    "        [17, 17],\n",
    "        [18, 18],\n",
    "        [19, 19],\n",
    "        [21, 21],\n",
    "        [22, 22],\n",
    "        [23, 23],\n",
    "        [24, 24],\n",
    "        [25, 25],\n",
    "        [26, 26],\n",
    "        [27, 27],\n",
    "        [28, 28],\n",
    "        [29, 29],\n",
    "        [32, 32],\n",
    "        [33, 33],\n",
    "        [34, 34],\n",
    "        [35, 35],\n",
    "        [36, 36],\n",
    "        [37, 37],\n",
    "        [38, 38],\n",
    "        [39, 39],\n",
    "        [40, 40],\n",
    "        [41, 41],\n",
    "        [42, 42],\n",
    "        [43, 43]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_trigger, true_label, pi_golden = true_label_and_trigger(train_x=train_x,train_y=train_y,train_masks=train_masks,train_span=train_span,class_num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_golden[3][30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi_star weighted by golden matrix (sum along axis 1):\n",
      "[0.7 0.5 0.3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Giả sử bạn có các ma trận sau:\n",
    "# pi_star: Ma trận alignment (sau khi tính toán thông qua OT)\n",
    "pi_star = np.array([[0.3, 0.7, 0.1],\n",
    "                    [0.5, 0.4, 0.1],\n",
    "                    [0.2, 0.6, 0.3]])\n",
    "\n",
    "# pi_g: Ma trận golden (true trigger labels)\n",
    "pi_g = np.array([[0, 1, 0],  # w1 có nhãn đúng là t2\n",
    "                 [1, 0, 0],  # w2 có nhãn đúng là t1\n",
    "                 [0, 0, 1]]) # w3 có nhãn đúng là t3\n",
    "\n",
    "# Nhân ma trận pi_star với pi_g (theo từng phần tử)\n",
    "pi_star_weighted = pi_star * pi_g\n",
    "\n",
    "# Tính tổng theo chiều ngang (axis=1)\n",
    "pi_star_sum = pi_star_weighted.sum(axis=1)\n",
    "\n",
    "print(\"Pi_star weighted by golden matrix (sum along axis 1):\")\n",
    "print(pi_star_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_star_1 = torch.tensor([\n",
    "    [[0.3, 0.7, 0.1,-1.0], [0.5, 0.4, 0.1,-1.0], [0.2, 0.6, 0.3,-1.0]],\n",
    "    [[0.5, 0.4, 0.1,-2.0], [0.3, 0.7, 0.1,-2.0], [0.2, 0.6, 0.3,-2.0]]]\n",
    ")\n",
    "pi_star_2 = torch.tensor([\n",
    "    [[0.3, 0.7, 0.1,-1.0], [0.5, 0.4, 0.1,-1.0], [0.2, 0.6, 0.3,-1.0]],\n",
    "    [[0.5, 0.4, 0.1,-2.0], [0.3, 0.7, 0.1,-2.0], [0.2, 0.6, 0.3,-2.0]]]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6357)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def L_task(pi_star, y_true):\n",
    "    \"\"\"\n",
    "    Tính Loss Task (Negative Log-Likelihood Loss) cho mỗi batch dữ liệu.\n",
    "\n",
    "    Arguments:\n",
    "    - pi_star (Tensor): Tensor có kích thước (batch_size, seq_len), chứa xác suất dự đoán cho từng từ và nhãn.\n",
    "    - y_true (Tensor): Tensor có kích thước (batch_size, seq_len), chứa nhãn thực tế (labels) cho từng từ.\n",
    "\n",
    "    Return:\n",
    "    - loss (Tensor): giá trị loss trung bình cho cả batch.\n",
    "    \"\"\"\n",
    "\n",
    "    # Chỉ tính log của pi_star mà không có phần (1 - pi_star)\n",
    "    loss = -torch.log((torch.sum(pi_star*y_true,dim=-1))).mean()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Ví dụ sử dụng:\n",
    "batch_size = 2  # Số câu trong batch\n",
    "seq_len = 4  # Số từ trong mỗi câu\n",
    "\n",
    "# Giả sử chúng ta có xác suất pi_star và nhãn thực tế y_true cho mỗi câu trong batch\n",
    "pi_star = torch.tensor(\n",
    "    [\n",
    "        [[0.3, 0.7, 0.1, -1.0], [0.5, 0.4, 0.1, -1.0], [0.2, 0.6, 0.3, -1.0]],\n",
    "        [[0.5, 0.4, 0.1, -2.0], [0.3, 0.7, 0.1, -2.0], [0.2, 0.6, 0.3, -2.0]],\n",
    "    ]\n",
    ")\n",
    "\n",
    "y_true = torch.tensor(\n",
    "    [\n",
    "        [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 1, 0]],\n",
    "        [[1, 0, 0, 0], [0, 1, 0, 0], [0, 1, 0, 0]],\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Tính L_task\n",
    "loss_task = L_task(pi_star, y_true)\n",
    "print(loss_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6357)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs = torch.sum(pi_star * y_true, dim=-1)\n",
    "log_probs = torch.log(log_probs + 1e-10)\n",
    "loss = -log_probs.mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6357)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-torch.log((torch.sum(pi_star*y_true,dim=-1))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0000, -0.3567, -0.0000,     nan],\n",
       "         [-0.6931, -0.0000, -0.0000,     nan],\n",
       "         [-0.0000, -0.0000, -1.2040,     nan]],\n",
       "\n",
       "        [[-0.6931, -0.0000, -0.0000,     nan],\n",
       "         [-0.0000, -0.3567, -0.0000,     nan],\n",
       "         [-0.0000, -0.5108, -0.0000,     nan]]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(pi_star)*y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul = -torch.log(pi_star_1*pi_star_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.4079,  0.7133,  4.6052, -0.0000],\n",
       "         [ 1.3863,  1.8326,  4.6052, -0.0000],\n",
       "         [ 3.2189,  1.0217,  2.4079, -0.0000]],\n",
       "\n",
       "        [[ 1.3863,  1.8326,  4.6052, -1.3863],\n",
       "         [ 2.4079,  0.7133,  4.6052, -1.3863],\n",
       "         [ 3.2189,  1.0217,  2.4079, -1.3863]]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8499, 1.5033])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul.sum(dim=[1,2])/(mul.size(1)*mul.size(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_star.sum(dim=-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_instance = {\n",
    "    \"piece_ids\": train_x[3],\n",
    "    \"label\": train_y[3],\n",
    "    \"span\": train_span[3],\n",
    "    \"mask\": train_masks[3],\n",
    "}\n",
    "# a, b = get_one_hot_true_label_and_true_trigger(data_instance=data_instance,num_label=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_word_is_label = torch.zeros(len(data_instance['piece_ids']),10)\n",
    "for i in range(len(data_instance[\"label\"])):\n",
    "    if data_instance[\"label\"][i] != 0:\n",
    "        # print(data_instance[\"label\"][i])\n",
    "\n",
    "    #     true_label.append(data_instance[\"label\"][i])\n",
    "    #     true_trigger.append(data_instance[\"span\"][i])\n",
    "        for word_is_trigger in data_instance['span'][i]:\n",
    "            # print(word_is_trigger)\n",
    "            matrix_word_is_label[word_is_trigger,data_instance['label'][i]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_word_is_label[20:33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_span)):\n",
    "    print(train_span[i].size(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "test = [torch.tensor([[1,2,3],[4,5,6]]),torch.tensor([[7,8,9],[10,11,12]])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Giả sử bạn có các tensor sau:\n",
    "# `last_hidden_state` có kích thước [batch_size, seqlen, hidden_dim]\n",
    "last_hidden_state = torch.randn(4, 122, 768)  # Kích thước giả định\n",
    "\n",
    "# `mask` có kích thước [batch_size, seqlen], giá trị 1 cho token thực sự và 0 cho padding\n",
    "mask = torch.randint(0, 2, (4, 122))  # Ví dụ: 1 cho token thực sự, 0 cho padding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_hidden_state_without_padding(last_hidden_state, masks):\n",
    "    masks = masks.unsqueeze(-1)\n",
    "    mask_hidden_state = last_hidden_state * masks\n",
    "    true_hidden_state_without_padding = mask_hidden_state.view(-1, 768)[\n",
    "        masks.view(-1) == 1\n",
    "    ]\n",
    "    return true_hidden_state_without_padding  # [sum_true_token, hidden_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_embedding = get_true_hidden_state_without_padding(last_hidden_state,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_hidden_state = last_hidden_state * mask.unsqueeze(-1)\n",
    "masked_hidden_state.size()\n",
    "masked_hidden_state = masked_hidden_state.view(-1, 768)[mask.view(-1) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([249, 768])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_hidden_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([249, 768])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_embedding.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giả sử bạn có các tensor như sau:\n",
    "batch_size = 4\n",
    "seq_len = 6\n",
    "\n",
    "# Các xác suất trigger cho từng token trong câu (p_wi)\n",
    "p_wi = torch.sigmoid(torch.randn(batch_size, seq_len))  # [4, 6]\n",
    "\n",
    "# Các nhãn thực tế (true_trig)\n",
    "true_trig = torch.randint(0, 2, (batch_size, seq_len))  # [4, 6] với giá trị 0 hoặc 1\n",
    "\n",
    "# Attention mask (masks), 1 cho token thực, 0 cho token padding\n",
    "masks = torch.tensor([[1, 1, 1, 1, 0, 0],  # Câu 1 có 4 token thực\n",
    "                      [1, 1, 1, 0, 0, 0],  # Câu 2 có 3 token thực\n",
    "                      [1, 1, 1, 1, 1, 0],  # Câu 3 có 5 token thực\n",
    "                      [1, 1, 1, 1, 1, 1]]) # Câu 4 có 6 token thực (không có padding)\n",
    "\n",
    "# Tính loss TI\n",
    "# loss = compute_loss_TI(p_wi, true_trig, masks)\n",
    "# print(\"Loss TI:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8904, 0.4555, 0.2070])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_wi[1][masks[1] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "seq_len = 5\n",
    "num_classes = 3\n",
    "\n",
    "# Tạo dữ liệu giả cho pi_star và pi_golden (giả sử xác suất phân bố đều cho pi_star, và pi_golden là các vector nhãn)\n",
    "pi_star = torch.rand(batch_size, seq_len, num_classes)  # Xác suất dự đoán ngẫu nhiên từ [0, 1]\n",
    "pi_star = pi_star / pi_star.sum(dim=-1, keepdim=True)  # Chuẩn hóa về tổng = 1 (xác suất)\n",
    "\n",
    "pi_golden = torch.randint(0, 2, (batch_size, seq_len, num_classes)).float()  # Nhãn thực (0 hoặc 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1151, 0.4943, 1.0000, 0.3761, 0.3852],\n",
       "        [0.4031, 0.7366, 1.0000, 0.8397, 0.1146],\n",
       "        [1.0000, 0.6542, 0.8769, 1.0000, 0.4036],\n",
       "        [0.8367, 0.6056, 0.7390, 0.0000, 0.3532]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(pi_golden*pi_star,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.1151, 0.0000],\n",
       "         [0.1963, 0.2979, 0.0000],\n",
       "         [0.2573, 0.4445, 0.2983],\n",
       "         [0.0000, 0.3761, 0.0000],\n",
       "         [0.0000, 0.3852, 0.0000]],\n",
       "\n",
       "        [[0.4031, 0.0000, 0.0000],\n",
       "         [0.0000, 0.3005, 0.4361],\n",
       "         [0.4377, 0.2548, 0.3074],\n",
       "         [0.3200, 0.0000, 0.5196],\n",
       "         [0.0246, 0.0000, 0.0900]],\n",
       "\n",
       "        [[0.2333, 0.3558, 0.4110],\n",
       "         [0.1819, 0.0000, 0.4723],\n",
       "         [0.6229, 0.0000, 0.2540],\n",
       "         [0.2883, 0.2216, 0.4901],\n",
       "         [0.0000, 0.0000, 0.4036]],\n",
       "\n",
       "        [[0.0000, 0.3779, 0.4588],\n",
       "         [0.0000, 0.6056, 0.0000],\n",
       "         [0.2351, 0.5038, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000],\n",
       "         [0.3532, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_golden*pi_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn_pytorch(M, a, b, lambda_sh, numItermax=1000, stopThr=5e-3):\n",
    "    u = torch.ones_like(a) / a.size(0)\n",
    "    v = torch.zeros_like(b)\n",
    "    K = torch.exp(-M * lambda_sh)\n",
    "\n",
    "    cpt = 0\n",
    "    err = 1.0\n",
    "\n",
    "    def condition(cpt, u, v, err):\n",
    "        return cpt < numItermax and err > stopThr\n",
    "\n",
    "    def v_update(u, v):\n",
    "        v = b / torch.matmul(K.t(), u)\n",
    "        u = a / torch.matmul(K, v)\n",
    "        return u, v\n",
    "\n",
    "    def no_v_update(u, v):\n",
    "        return u, v\n",
    "\n",
    "    def err_f1(K, u, v, b):\n",
    "        bb = v * torch.matmul(K.t(), u)\n",
    "        err = torch.norm(torch.sum(torch.abs(bb - b), dim=0), p=float('inf'))\n",
    "        return err\n",
    "\n",
    "    def err_f2(err):\n",
    "        return err\n",
    "\n",
    "    def loop_func(cpt, u, v, err):\n",
    "        u = a / torch.matmul(K, b / torch.matmul(u.T, K).T)\n",
    "        cpt = cpt + 1\n",
    "        if cpt % 20 == 1 or cpt == numItermax:\n",
    "            u, v = v_update(u, v)\n",
    "            err = err_f1(K, u, v, b)\n",
    "        else:\n",
    "            u, v = no_v_update(u, v)\n",
    "            err = err_f2(err)\n",
    "        return cpt, u, v, err\n",
    "\n",
    "    while condition(cpt, u, v, err):\n",
    "        cpt, u, v, err = loop_func(cpt, u, v, err)\n",
    "\n",
    "    sinkhorn_divergences = torch.sum(u * torch.matmul(K * M, v), dim=0)\n",
    "    return sinkhorn_divergences\n",
    "\n",
    "def compute_pi_star(M, a, b, lambda_sh, numItermax=1000, stopThr=5e-3):\n",
    "    # Gọi hàm Sinkhorn để tính u, v và ma trận K\n",
    "    u, v, K = sinkhorn_pytorch(M, a, b, lambda_sh, numItermax, stopThr)\n",
    "    \n",
    "    # Tính ma trận đồng nhất tối ưu pi_star bằng công thức pi_star = diag(u) * K * diag(v)\n",
    "    pi_star = torch.diag(u) @ K @ torch.diag(v)\n",
    "    \n",
    "    return pi_star\n",
    "\n",
    "# batch_size = 4\n",
    "# num_class = 11\n",
    "# num_token = 122\n",
    "\n",
    "# word_preference = torch.randn(batch_size,num_token)\n",
    "# type_preference = torch.randn(batch_size,num_class)\n",
    "# cost_matrix = torch.randn(batch_size,num_class,num_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class, num_token = 11, 122\n",
    "\n",
    "# Tạo ma trận chi phí ngẫu nhiên kích thước (n, m) = (11, 122)\n",
    "M = torch.rand(num_class, num_token)\n",
    "\n",
    "# Tạo các vector a và b là phân phối xác suất (tổng = 1)\n",
    "a = torch.tensor([1.0 / num_class] * num_class)  # Phân phối xác suất cho a (có tổng = 1)\n",
    "b = torch.tensor([1.0 / num_token] * num_token)  # Phân phối xác suất cho b (có tổng = 1)\n",
    "\n",
    "# Tham số điều chỉnh regularization\n",
    "lambda_sh = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 122, 11, 768])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn([4,122,768])\n",
    "y = torch.randn([11,768])\n",
    "(x.unsqueeze(2)-y.unsqueeze(0).unsqueeze(0)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=x.unsqueeze(2).repeat(1,1,11,1)\n",
    "y1=y.unsqueeze(0).unsqueeze(0).repeat(4,122,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 122, 11])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-torch.nn.functional.cosine_similarity(x1=x1,x2=y1,dim=3)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "test = torch.randint(1,20,(4,11,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 8, 1, 12, 7, 5, 17, 16, 11, 14, 13, 15, 6]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dict.fromkeys(test[0].flatten().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 8, 1, 12, 7, 1, 5, 17, 16, 11, 14, 1, 13, 5, 11, 5, 15, 2, 17, 6, 11, 1]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0].flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 8, 8, 1, 1, 12, 13, 7, 5, 17, 16, 11, 2, 14, 13, 15, 6]"
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [2, 2, 8, 8, 1, 1, 12, 13, 7, 5, 17, 16, 11,2, 14, 13, 15, 6]\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 8, 1, 12, 13, 7, 5, 17, 16, 11, 14, 15, 6]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dict.fromkeys(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand([4,122,768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([13, 768])"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][list(dict.fromkeys(a)),:].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Linear(768,1)\n",
    "input = torch.rand([17,768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.sigmoid(linear(input))\n",
    "output1 = (linear(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3153, -0.2226, -0.1029, -0.2959, -0.4649, -0.2998, -0.5438, -0.1999,\n",
       "        -0.1981, -0.6199, -0.4724, -0.2184, -0.0811, -0.1304, -0.4779, -0.1843,\n",
       "        -0.3864], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1.squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17, 1])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0576, 0.0632, 0.0713, 0.0588, 0.0496, 0.0585, 0.0458, 0.0647, 0.0648,\n",
       "        0.0425, 0.0492, 0.0635, 0.0728, 0.0693, 0.0490, 0.0657, 0.0537],\n",
       "       grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.softmax(output.squeeze(1),dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_y(y):\n",
    "    true_y = []\n",
    "    for i in range(len(y)):\n",
    "        filter_y = (y[i] != 0).int()\n",
    "        true_y.append(filter_y)\n",
    "    return true_y\n",
    "\n",
    "test = torch.randint(0,10,[4,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6, 9, 6, 3, 6, 7, 5, 4, 6, 6],\n",
       "        [6, 4, 7, 1, 3, 0, 1, 7, 9, 3],\n",
       "        [0, 0, 2, 1, 9, 3, 3, 9, 4, 7],\n",
       "        [9, 1, 3, 8, 7, 9, 7, 3, 6, 7]])"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32),\n",
       " tensor([1, 1, 1, 1, 1, 0, 1, 1, 1, 1], dtype=torch.int32),\n",
       " tensor([0, 0, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32),\n",
       " tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1], dtype=torch.int32)]"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_true_y(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6034)"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def compute_loss_TI(p_wi, true_y):\n",
    "    loss_TI = 0.0\n",
    "    for i in range(len(true_y)):\n",
    "        # mask padding token\n",
    "        loss_TI += -torch.dot(true_y[i].float(), torch.log(p_wi[i])) - torch.dot(\n",
    "            (1 - true_y[i].float()), torch.log(1 - p_wi[i])\n",
    "        )\n",
    "\n",
    "    return loss_TI / len(true_y)\n",
    "\n",
    "\n",
    "p_wi = [torch.tensor([0.9,0.05,0.1]), torch.tensor([0.6,0.1,0.1,0.2])]\n",
    "true_y = [torch.tensor([1,0,0]),torch.tensor([1,0,0,0])]\n",
    "compute_loss_TI(p_wi,true_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_y(y,num_class):\n",
    "    true_trig,true_label = [],[]\n",
    "    for i in range(len(y)):\n",
    "        true_label_loop = torch.zeros(num_class)\n",
    "        set_label = set(y[i].tolist())\n",
    "        for label in set_label:\n",
    "            if label != 0:\n",
    "                true_label_loop += torch.nn.functional.one_hot(torch.tensor(label),num_classes=num_class)\n",
    "        \n",
    "        filter_y = (y[i] != 0).int()\n",
    "        true_trig.append(filter_y)\n",
    "        true_label.append(true_label_loop)\n",
    "    return true_trig,true_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [torch.tensor([2,3,5,0,0,0]),torch.tensor([7,8,0]),torch.tensor([1,1,2,0])]\n",
    "num_class = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_trig, true_label =get_true_y(y,num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([1, 1, 1, 0, 0, 0], dtype=torch.int32),\n",
       " tensor([1, 1, 0], dtype=torch.int32),\n",
       " tensor([1, 1, 1, 0], dtype=torch.int32)]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_trig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([0., 0., 1., 1., 0., 1., 0., 0., 0., 0.]),\n",
       " tensor([0., 0., 0., 0., 0., 0., 0., 1., 1., 0.]),\n",
       " tensor([0., 1., 1., 0., 0., 0., 0., 0., 0., 0.])]"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def get_one_hot_true_label_and_true_trigger(data_instance, num_label):\n",
    "    true_label = []\n",
    "    true_trigger = []\n",
    "    seq_len = len(\n",
    "        data_instance[\"piece_ids\"]\n",
    "    )  # because start_index of piece_ids is 1 instead of 0\n",
    "    matrix_word_is_label = torch.zeros(seq_len, num_label, dtype=int)\n",
    "    for i in range(len(data_instance[\"label\"])):\n",
    "        if data_instance[\"label\"][i] != 0:\n",
    "            true_label.append(data_instance[\"label\"][i])\n",
    "            true_trigger.append(data_instance[\"span\"][i])\n",
    "            for word_is_trigger in data_instance[\"span\"][i]:\n",
    "                matrix_word_is_label[word_is_trigger, data_instance[\"label\"][i]] = 1\n",
    "\n",
    "    true_one_hot_label_vector = torch.zeros(num_label)\n",
    "    true_one_hot_trigger_vector = torch.zeros(seq_len)\n",
    "\n",
    "    set_label_in_one_sentence = set([label.item() for label in true_label])\n",
    "    for i in set_label_in_one_sentence:\n",
    "        true_one_hot_label_vector += torch.eye(num_label)[i]\n",
    "\n",
    "    list_trigger = [trigger.tolist() for trigger in true_trigger]\n",
    "    trigger = []\n",
    "    for i in list_trigger:\n",
    "        trigger.extend(i)\n",
    "\n",
    "    set_trig_in_one_sentence = set(trigger)\n",
    "\n",
    "    for i in set_trig_in_one_sentence:\n",
    "        true_one_hot_trigger_vector += torch.eye(seq_len)[i]\n",
    "    true_one_hot_trigger_vector = true_one_hot_trigger_vector.to(device)\n",
    "    true_one_hot_label_vector = true_one_hot_label_vector.to(device)\n",
    "    return true_one_hot_trigger_vector, true_one_hot_label_vector, matrix_word_is_label\n",
    "\n",
    "\n",
    "def true_label_and_trigger(train_x, train_y, train_masks, train_span, class_num):\n",
    "    num_instance = len(train_x)\n",
    "    true_one_hot_label_vectors = []\n",
    "    true_one_hot_trigger_vectors = []\n",
    "    golden_matrix = []\n",
    "    for i in range(num_instance):\n",
    "        data_instace = {\n",
    "            \"piece_ids\": train_x[i],\n",
    "            \"label\": train_y[i],\n",
    "            \"span\": train_span[i],\n",
    "            \"mask\": train_masks[i],\n",
    "        }\n",
    "\n",
    "        true_one_hot_trigger_vector, true_one_hot_label_vector, matrix_word_is_label = (\n",
    "            get_one_hot_true_label_and_true_trigger(\n",
    "                data_instance=data_instace, num_label=class_num\n",
    "            )\n",
    "        )\n",
    "        true_one_hot_trigger_vectors.append(true_one_hot_trigger_vector)\n",
    "        true_one_hot_label_vectors.append(true_one_hot_label_vector)\n",
    "        golden_matrix.append(matrix_word_is_label)\n",
    "    true_one_hot_trigger_vectors = torch.stack(\n",
    "        [x.to(device) for x in true_one_hot_trigger_vectors]\n",
    "    )\n",
    "    true_one_hot_label_vectors = torch.stack(\n",
    "        [x.to(device) for x in true_one_hot_label_vectors]\n",
    "    )\n",
    "    pi_golden_matrix = torch.stack([x.to(device) for x in golden_matrix])\n",
    "    return true_one_hot_trigger_vectors, true_one_hot_label_vectors, pi_golden_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_hidden_state_order = [torch.rand([11,768]),torch.rand([5,768]),torch.rand([6,768]),torch.rand(20,768)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_embedding = torch.rand([11,768])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 11, 768])"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_embedding.unsqueeze(0).repeat([5,1,1]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 11, 768])"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_hidden_state_order[1].unsqueeze(1).repeat([1,11,1]).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 11])"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-torch.nn.functional.cosine_similarity(label_embedding.unsqueeze(0).repeat([5,1,1]),last_hidden_state_order[1].unsqueeze(1).repeat([1,11,1]),dim=-1)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_transport(last_hidden_state_order, label_embedding, num_classes = 11):\n",
    "    # last_hidden_state_order: [batch_size, num_span, hidden_dim]\n",
    "    # label_embedding: [num_class, hidden_dim]\n",
    "    \n",
    "    batch_size = len(last_hidden_state_order)\n",
    "    cost_matrix = []\n",
    "    for i in range(batch_size):\n",
    "        num_span = last_hidden_state_order[i].size(0)\n",
    "        label_embedding_scale = label_embedding.unsqueeze(0).repeat([num_span,1,1])\n",
    "        last_hidden_state_order_scale = last_hidden_state_order[i].unsqueeze(1).repeat([1,num_classes,1])\n",
    "        cost = 1-torch.nn.functional.cosine_similarity(last_hidden_state_order_scale,label_embedding_scale,dim=-1)\n",
    "        cost_matrix.append(cost)\n",
    "    return cost_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost_matrix = compute_cost_transport(last_hidden_state_order=last_hidden_state_order,label_embedding=label_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of cost_matrix[0]: torch.Size([11, 11])\n",
      "size of cost_matrix[1]: torch.Size([5, 11])\n",
      "size of cost_matrix[2]: torch.Size([6, 11])\n",
      "size of cost_matrix[3]: torch.Size([20, 11])\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(cost_matrix)):\n",
    "    print(f'size of cost_matrix[{i}]: {cost_matrix[i].size()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = torch.nn.Linear(768,1)\n",
    "D_W_P = []\n",
    "for sentence in range(len(last_hidden_state_order)):\n",
    "    D_W_P.append(torch.softmax(torch.sigmoid(linear(last_hidden_state_order[sentence])).flatten(),dim=-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(D_W_P[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_cls = torch.rand([4,768])\n",
    "e_cls_scale = e_cls.unsqueeze(1).repeat([1,11,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 11, 768])"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e_cls_scale.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_embedding_scale = label_embedding.unsqueeze(0).repeat([4,1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "concat = torch.cat([e_cls_scale,label_embedding_scale],dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "ffp = torch.nn.Linear(768*2,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_T_P = torch.softmax(torch.sigmoid(ffp(concat).squeeze(-1)),dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.0000, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(D_T_P[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ot\n",
    "def compute_optimal_transport(p, q, C, epsilon=0.05):\n",
    "    device = p.device\n",
    "\n",
    "    p_i = p.detach().cpu().numpy()\n",
    "    q_i = q.detach().cpu().numpy()\n",
    "    C_i = C.detach().cpu().numpy()\n",
    "\n",
    "    pi_i = ot.sinkhorn(p_i, q_i, C_i, reg=epsilon)\n",
    "\n",
    "    pi_i_tensor = torch.tensor(pi_i, device=device)\n",
    "\n",
    "    return pi_i_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0921, 0.0961, 0.0943, 0.0922, 0.0912, 0.0915, 0.0877, 0.0861, 0.0822,\n",
      "        0.0953, 0.0914], grad_fn=<SoftmaxBackward0>)\n",
      "tensor([0.0918, 0.0882, 0.0929, 0.0894, 0.0941, 0.0892, 0.0920, 0.0894, 0.0907,\n",
      "        0.0916, 0.0907], grad_fn=<SelectBackward0>)\n",
      "tensor([[0.2582, 0.2447, 0.2369, 0.2448, 0.2562, 0.2636, 0.2619, 0.2515, 0.2402,\n",
      "         0.2487, 0.2451],\n",
      "        [0.2566, 0.2528, 0.2547, 0.2515, 0.2473, 0.2396, 0.2482, 0.2400, 0.2459,\n",
      "         0.2446, 0.2357],\n",
      "        [0.2433, 0.2444, 0.2473, 0.2426, 0.2496, 0.2442, 0.2377, 0.2474, 0.2523,\n",
      "         0.2609, 0.2431],\n",
      "        [0.2412, 0.2486, 0.2462, 0.2530, 0.2683, 0.2550, 0.2419, 0.2410, 0.2575,\n",
      "         0.2339, 0.2480],\n",
      "        [0.2692, 0.2484, 0.2487, 0.2553, 0.2570, 0.2561, 0.2587, 0.2569, 0.2745,\n",
      "         0.2466, 0.2502],\n",
      "        [0.2492, 0.2455, 0.2577, 0.2404, 0.2465, 0.2552, 0.2486, 0.2314, 0.2603,\n",
      "         0.2404, 0.2526],\n",
      "        [0.2706, 0.2537, 0.2363, 0.2622, 0.2615, 0.2597, 0.2703, 0.2486, 0.2498,\n",
      "         0.2531, 0.2637],\n",
      "        [0.2617, 0.2512, 0.2416, 0.2437, 0.2407, 0.2379, 0.2499, 0.2319, 0.2581,\n",
      "         0.2487, 0.2485],\n",
      "        [0.2428, 0.2718, 0.2489, 0.2628, 0.2479, 0.2384, 0.2459, 0.2548, 0.2578,\n",
      "         0.2620, 0.2306],\n",
      "        [0.2512, 0.2411, 0.2631, 0.2454, 0.2564, 0.2249, 0.2464, 0.2427, 0.2435,\n",
      "         0.2655, 0.2357],\n",
      "        [0.2515, 0.2465, 0.2444, 0.2596, 0.2401, 0.2355, 0.2340, 0.2434, 0.2350,\n",
      "         0.2432, 0.2404]])\n"
     ]
    }
   ],
   "source": [
    "print(D_W_P[0])\n",
    "print(D_T_P[0])\n",
    "print(cost_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nhatminhnguyen/anaconda3/envs/natmin/lib/python3.11/site-packages/ot/bregman/_sinkhorn.py:531: UserWarning: Sinkhorn did not converge. You might want to increase the number of iterations `numItermax` or the regularization parameter `reg`.\n",
      "  warnings.warn(\"Sinkhorn did not converge. You might want to \"\n"
     ]
    }
   ],
   "source": [
    "pi_i = compute_optimal_transport(D_W_P[0],D_T_P[0],cost_matrix[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 11])"
      ]
     },
     "execution_count": 437,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_i.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 11])\n",
      "torch.Size([5, 11])\n",
      "torch.Size([6, 11])\n",
      "torch.Size([20, 11])\n"
     ]
    }
   ],
   "source": [
    "pi_star = []\n",
    "for sentence in range(len(D_W_P)):\n",
    "    pi_i = compute_optimal_transport(D_W_P[sentence],D_T_P[sentence],cost_matrix[sentence])\n",
    "    print(pi_i.size())\n",
    "    pi_star.append(pi_i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 11])"
      ]
     },
     "execution_count": 440,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_star[0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 1, 0, 2, 1])"
      ]
     },
     "execution_count": 457,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_y_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0156, 0.0163, 0.0175, 0.0116, 0.0145, 0.0117, 0.0144, 0.0162, 0.0179,\n",
       "         0.0147, 0.0167],\n",
       "        [0.0143, 0.0193, 0.0125, 0.0198, 0.0181, 0.0120, 0.0152, 0.0175, 0.0158,\n",
       "         0.0135, 0.0192],\n",
       "        [0.0169, 0.0132, 0.0133, 0.0175, 0.0171, 0.0154, 0.0146, 0.0175, 0.0179,\n",
       "         0.0150, 0.0152],\n",
       "        [0.0155, 0.0158, 0.0168, 0.0133, 0.0146, 0.0143, 0.0155, 0.0131, 0.0137,\n",
       "         0.0170, 0.0110],\n",
       "        [0.0150, 0.0121, 0.0126, 0.0138, 0.0134, 0.0193, 0.0117, 0.0091, 0.0139,\n",
       "         0.0174, 0.0168],\n",
       "        [0.0145, 0.0116, 0.0201, 0.0134, 0.0163, 0.0165, 0.0206, 0.0161, 0.0114,\n",
       "         0.0140, 0.0118]])"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_star[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_y_3 = torch.randint(0,3,[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6])"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_y_3.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 11])"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_star[2].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(25.8244)"
      ]
     },
     "execution_count": 467,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(-torch.log(pi_star[2].gather(1,true_y_3.unsqueeze(1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.9933)"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "natmin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
