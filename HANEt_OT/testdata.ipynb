{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "\n",
    "args_perm_id = 0\n",
    "args_task_num = 5\n",
    "args_class_num = 10\n",
    "args_shot_num = 5\n",
    "def collect_from_json(dataset, root, split):\n",
    "    if split == \"train\":\n",
    "        pth = os.path.join(\n",
    "            root,\n",
    "            dataset,\n",
    "            \"perm\" + str(args_perm_id),\n",
    "            f\"{dataset}_{args_task_num}task_{args_class_num // args_task_num}way_{args_shot_num}shot.{split}.jsonl\",\n",
    "        )\n",
    "    elif split in [\"dev\", \"test\"]:\n",
    "        pth = os.path.join(root, dataset, f\"{dataset}.{split}.jsonl\")\n",
    "    elif split == \"stream\":\n",
    "        pth = os.path.join(\n",
    "            root,\n",
    "            dataset,\n",
    "            f\"stream_label_{args_task_num}task_{args_class_num // args_task_num}way.json\",\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f'Split \"{split}\" value wrong!')\n",
    "    if not os.path.exists(pth):\n",
    "        raise FileNotFoundError(f\"Path {pth} do not exist!\")\n",
    "    else:\n",
    "        with open(pth) as f:\n",
    "            if pth.endswith(\".jsonl\"):\n",
    "                data = [json.loads(line) for line in f]\n",
    "                if split == \"train\":\n",
    "                    data = [list(i.values()) for i in data]\n",
    "            else:\n",
    "                data = json.load(f)\n",
    "    # if split == \"train\":\n",
    "    #     data = extract_single_dict(data)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'ACE'\n",
    "root = './data_incremental'\n",
    "split = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [instance for t in collect_from_json(dataset, root, split)[1] for instance in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def get_one_hot_true_label_and_true_trigger(data_instance, num_label):\n",
    "    true_label = []\n",
    "    trigger_word = []\n",
    "    seq_len = len(data_instance[\"piece_ids\"]) + 1 # because start_index of piece_ids is 1 instead of 0\n",
    "    for i in range(len(data_instance[\"label\"])):\n",
    "        if data_instance[\"label\"][i] != 0:\n",
    "            true_label.append(data_instance[\"label\"][i])\n",
    "            trigger_word.append(data_instance[\"span\"][i])\n",
    "\n",
    "    set_label_in_one_sentence = set(true_label)\n",
    "    true_one_hot_trigger_vector = torch.zeros(num_label)\n",
    "    for i in set_label_in_one_sentence:\n",
    "        true_one_hot_trigger_vector += torch.eye(num_label)[i]\n",
    "\n",
    "    true_one_hot_label_vector = torch.zeros(seq_len)\n",
    "    trigger = []\n",
    "    for i in trigger_word:\n",
    "        trigger.extend(i)\n",
    "\n",
    "    set_trig = set(trigger)\n",
    "    for i in set_trig:\n",
    "        true_one_hot_label_vector += torch.eye(seq_len)[i]\n",
    "    return true_one_hot_trigger_vector, true_one_hot_label_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = get_one_hot_true_label_and_true_trigger(data[0],10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 0., 0., 0., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "47\n",
      "47\n"
     ]
    }
   ],
   "source": [
    "print(len(data[0]['piece_ids']))\n",
    "print(len(data[0]['label']))\n",
    "print(len(data[0]['span']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "for instance in data:\n",
    "    true_one_hot_trigger_vector, true_one_hot_label_vector = get_one_hot_true_label_and_true_trigger(instance, 10)\n",
    "    instance['true_one_hot_trigger_vector'] = true_one_hot_trigger_vector.tolist()\n",
    "    instance['true_one_hot_label_vector'] = true_one_hot_label_vector.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'piece_ids': [101,\n",
       "  3960,\n",
       "  1010,\n",
       "  1045,\n",
       "  2228,\n",
       "  2008,\n",
       "  1996,\n",
       "  3114,\n",
       "  7955,\n",
       "  1999,\n",
       "  1996,\n",
       "  2148,\n",
       "  1011,\n",
       "  1011,\n",
       "  2017,\n",
       "  2113,\n",
       "  1010,\n",
       "  2034,\n",
       "  1997,\n",
       "  2035,\n",
       "  1010,\n",
       "  2057,\n",
       "  2020,\n",
       "  1011,\n",
       "  1011,\n",
       "  2043,\n",
       "  5951,\n",
       "  8573,\n",
       "  2001,\n",
       "  2700,\n",
       "  2343,\n",
       "  1010,\n",
       "  2057,\n",
       "  2018,\n",
       "  2042,\n",
       "  2542,\n",
       "  2054,\n",
       "  2057,\n",
       "  2245,\n",
       "  2001,\n",
       "  2145,\n",
       "  1037,\n",
       "  11438,\n",
       "  3842,\n",
       "  2044,\n",
       "  1996,\n",
       "  2942,\n",
       "  2162,\n",
       "  1012,\n",
       "  102],\n",
       " 'label': [6,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0],\n",
       " 'span': [[29, 29],\n",
       "  [46, 47],\n",
       "  [1, 1],\n",
       "  [2, 2],\n",
       "  [3, 3],\n",
       "  [4, 4],\n",
       "  [5, 5],\n",
       "  [6, 6],\n",
       "  [7, 7],\n",
       "  [8, 8],\n",
       "  [9, 9],\n",
       "  [10, 10],\n",
       "  [11, 11],\n",
       "  [12, 12],\n",
       "  [13, 13],\n",
       "  [14, 14],\n",
       "  [15, 15],\n",
       "  [16, 16],\n",
       "  [17, 17],\n",
       "  [18, 18],\n",
       "  [19, 19],\n",
       "  [20, 20],\n",
       "  [21, 21],\n",
       "  [22, 22],\n",
       "  [23, 23],\n",
       "  [24, 24],\n",
       "  [25, 25],\n",
       "  [26, 26],\n",
       "  [27, 27],\n",
       "  [28, 28],\n",
       "  [30, 30],\n",
       "  [31, 31],\n",
       "  [32, 32],\n",
       "  [33, 33],\n",
       "  [34, 34],\n",
       "  [35, 35],\n",
       "  [36, 36],\n",
       "  [37, 37],\n",
       "  [38, 38],\n",
       "  [39, 39],\n",
       "  [40, 40],\n",
       "  [41, 41],\n",
       "  [42, 42],\n",
       "  [43, 43],\n",
       "  [44, 44],\n",
       "  [45, 45],\n",
       "  [48, 48]],\n",
       " 'true_one_hot_trigger_vector': [0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0],\n",
       " 'true_one_hot_label_vector': [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0]}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def get_one_hot_true_label_and_true_trigger(data_instance, num_label):\n",
    "    true_label = []\n",
    "    true_trigger = []\n",
    "    seq_len = len(data_instance[\"piece_ids\"]) # because start_index of piece_ids is 1 instead of 0\n",
    "    \n",
    "    for i in range(len(data_instance[\"label\"])):\n",
    "        if data_instance[\"label\"][i] != 0:\n",
    "            true_label.append(data_instance[\"label\"][i])\n",
    "            true_trigger.append(data_instance[\"span\"][i])\n",
    "\n",
    "\n",
    "    true_one_hot_label_vector = torch.zeros(num_label)\n",
    "    true_one_hot_trigger_vector = torch.zeros(seq_len)\n",
    "\n",
    "    set_label_in_one_sentence = set([label.item() for label in true_label])\n",
    "    for i in set_label_in_one_sentence:\n",
    "        true_one_hot_label_vector += torch.eye(num_label)[i]\n",
    "\n",
    "\n",
    "    list_trigger = [trigger.tolist() for trigger in true_trigger]\n",
    "    trigger = []\n",
    "    for i in list_trigger:\n",
    "        trigger.extend(i)\n",
    "\n",
    "    set_trig_in_one_sentence = set(trigger)\n",
    "\n",
    "    for i in set_trig_in_one_sentence:\n",
    "        true_one_hot_trigger_vector += torch.eye(seq_len)[i]\n",
    "    \n",
    "    return true_one_hot_trigger_vector, true_one_hot_label_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "def get_one_hot_true_label_and_true_trigger(data_instance, num_label):\n",
    "    true_label = []\n",
    "    true_trigger = []\n",
    "    seq_len = len(data_instance[\"piece_ids\"]) # because start_index of piece_ids is 1 instead of 0\n",
    "    matrix_word_is_label = torch.zeros(seq_len, num_label,dtype=int)\n",
    "    for i in range(len(data_instance[\"label\"])):\n",
    "        if data_instance[\"label\"][i] != 0:\n",
    "            true_label.append(data_instance[\"label\"][i])\n",
    "            true_trigger.append(data_instance[\"span\"][i])\n",
    "            for word_is_trigger in data_instance['span'][i]:\n",
    "                matrix_word_is_label[word_is_trigger,data_instance['label'][i]] = 1\n",
    "\n",
    "\n",
    "    true_one_hot_label_vector = torch.zeros(num_label)\n",
    "    true_one_hot_trigger_vector = torch.zeros(seq_len)\n",
    "\n",
    "    set_label_in_one_sentence = set([label.item() for label in true_label])\n",
    "    for i in set_label_in_one_sentence:\n",
    "        true_one_hot_label_vector += torch.eye(num_label)[i]\n",
    "\n",
    "\n",
    "    list_trigger = [trigger.tolist() for trigger in true_trigger]\n",
    "    trigger = []\n",
    "    for i in list_trigger:\n",
    "        trigger.extend(i)\n",
    "\n",
    "    set_trig_in_one_sentence = set(trigger)\n",
    "\n",
    "    for i in set_trig_in_one_sentence:\n",
    "        true_one_hot_trigger_vector += torch.eye(seq_len)[i]\n",
    "    true_one_hot_trigger_vector = true_one_hot_trigger_vector.to(device)\n",
    "    true_one_hot_label_vector = true_one_hot_label_vector.to(device)\n",
    "    matrix_word_is_label = matrix_word_is_label.to(device)\n",
    "    return true_one_hot_trigger_vector, true_one_hot_label_vector, matrix_word_is_label\n",
    "\n",
    "def true_label_and_trigger(train_x,train_y,train_masks, train_span, class_num):\n",
    "    num_instance = len(train_x)\n",
    "    true_one_hot_label_vectors = []\n",
    "    true_one_hot_trigger_vectors = []\n",
    "    golden_matrix = []\n",
    "    for i in range(num_instance):\n",
    "        data_instace={\n",
    "            'piece_ids': train_x[i],\n",
    "            'label': train_y[i],\n",
    "            'span': train_span[i],\n",
    "            'mask': train_masks[i]\n",
    "        }\n",
    "\n",
    "        true_one_hot_trigger_vector, true_one_hot_label_vector, matrix_word_is_label= get_one_hot_true_label_and_true_trigger(data_instance=data_instace,num_label=class_num)\n",
    "        true_one_hot_trigger_vectors.append(true_one_hot_trigger_vector)\n",
    "        true_one_hot_label_vectors.append(true_one_hot_label_vector)\n",
    "        golden_matrix.append(matrix_word_is_label)\n",
    "    true_one_hot_trigger_vectors = torch.stack([x.to(device) for x in true_one_hot_trigger_vectors])\n",
    "    true_one_hot_label_vectors = torch.stack([x.to(device) for x in true_one_hot_label_vectors])\n",
    "    pi_golden_matrix = torch.stack([x.to(device) for x in golden_matrix])\n",
    "    return true_one_hot_trigger_vectors, true_one_hot_label_vectors, pi_golden_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "train_x = torch.tensor([[  101,  6398,  1024,  6175,  2003,  2025,  1996,  2069,  2510,  2564,\n",
    "          2040,  2363,  1037,  6302,  1998,  3661,  1012,   102,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0],\n",
    "        [  101, 21524,  1998,  2037,  2079, 24968,  5611,  6956, 19974,  2224,\n",
    "          1996,  2773,  1036,  1036,  6139,  1005,  1005,  2043,  9694,  2008,\n",
    "          3956,  2681,  1996,  2225,  2924,  1998, 14474,  1998,  4487, 11512,\n",
    "          9286,  3644,  7617,  1012,   102,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0],\n",
    "        [  101,  1045,  2079,  1050,  1005,  1056,  2228,  2008,  1005,  1055,\n",
    "          3243,  8321,  2004,  2000,  2054,  2002,  2626,  2033,  2055,  1012,\n",
    "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0],\n",
    "        [  101,  2358, 23111,  6582,  1010,  2040,  2001,  2809,  2706,  6875,\n",
    "          1010,  2018,  3041,  2042,  3331,  2007,  2014,  2388,  2006,  1996,\n",
    "          3042,  1010,  1998,  5112,  2039,  3038,  1037,  2450,  2016,  2018,\n",
    "         11834,  3064,  2007,  3784,  2018,  2074,  3369,  2012,  2014,  2341,\n",
    "          1010,  4614,  2056,  1012,   102,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
    "             0,     0]])\n",
    "\n",
    "train_y = [torch.tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), torch.tensor([2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0, 0, 0, 0, 0]), torch.tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), torch.tensor([1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])]\n",
    "train_masks = torch.tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0],\n",
    "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
    "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    "         0, 0]])\n",
    "train_span = [torch.tensor([[15, 15],\n",
    "        [ 1,  1],\n",
    "        [ 2,  2],\n",
    "        [ 3,  3],\n",
    "        [ 4,  4],\n",
    "        [ 5,  5],\n",
    "        [ 6,  6],\n",
    "        [ 7,  7],\n",
    "        [ 8,  8],\n",
    "        [ 9,  9],\n",
    "        [10, 10],\n",
    "        [11, 11],\n",
    "        [12, 12],\n",
    "        [13, 13],\n",
    "        [14, 14],\n",
    "        [16, 16]]), torch.tensor([[21, 21],\n",
    "        [ 1,  1],\n",
    "        [ 2,  2],\n",
    "        [ 3,  3],\n",
    "        [ 4,  4],\n",
    "        [ 5,  5],\n",
    "        [ 6,  6],\n",
    "        [ 7,  7],\n",
    "        [ 8,  8],\n",
    "        [ 9,  9],\n",
    "        [10, 10],\n",
    "        [11, 11],\n",
    "        [12, 12],\n",
    "        [13, 13],\n",
    "        [14, 14],\n",
    "        [15, 15],\n",
    "        [16, 16],\n",
    "        [17, 17],\n",
    "        [18, 18],\n",
    "        [19, 19],\n",
    "        [20, 20],\n",
    "        [22, 22],\n",
    "        [23, 23],\n",
    "        [24, 24],\n",
    "        [25, 25],\n",
    "        [26, 26],\n",
    "        [27, 27],\n",
    "        [28, 28],\n",
    "        [29, 29],\n",
    "        [30, 30],\n",
    "        [31, 31],\n",
    "        [32, 32],\n",
    "        [33, 33]]), torch.tensor([[16, 16],\n",
    "        [ 1,  1],\n",
    "        [ 2,  2],\n",
    "        [ 3,  3],\n",
    "        [ 4,  4],\n",
    "        [ 5,  5],\n",
    "        [ 6,  6],\n",
    "        [ 7,  7],\n",
    "        [ 8,  8],\n",
    "        [ 9,  9],\n",
    "        [10, 10],\n",
    "        [11, 11],\n",
    "        [12, 12],\n",
    "        [13, 13],\n",
    "        [14, 14],\n",
    "        [15, 15],\n",
    "        [17, 17],\n",
    "        [18, 18],\n",
    "        [19, 19]]), torch.tensor([[20, 20],\n",
    "        [30, 31],\n",
    "        [ 1,  1],\n",
    "        [ 2,  2],\n",
    "        [ 3,  3],\n",
    "        [ 4,  4],\n",
    "        [ 5,  5],\n",
    "        [ 6,  6],\n",
    "        [ 7,  7],\n",
    "        [ 8,  8],\n",
    "        [ 9,  9],\n",
    "        [10, 10],\n",
    "        [11, 11],\n",
    "        [12, 12],\n",
    "        [13, 13],\n",
    "        [14, 14],\n",
    "        [15, 15],\n",
    "        [16, 16],\n",
    "        [17, 17],\n",
    "        [18, 18],\n",
    "        [19, 19],\n",
    "        [21, 21],\n",
    "        [22, 22],\n",
    "        [23, 23],\n",
    "        [24, 24],\n",
    "        [25, 25],\n",
    "        [26, 26],\n",
    "        [27, 27],\n",
    "        [28, 28],\n",
    "        [29, 29],\n",
    "        [32, 32],\n",
    "        [33, 33],\n",
    "        [34, 34],\n",
    "        [35, 35],\n",
    "        [36, 36],\n",
    "        [37, 37],\n",
    "        [38, 38],\n",
    "        [39, 39],\n",
    "        [40, 40],\n",
    "        [41, 41],\n",
    "        [42, 42],\n",
    "        [43, 43]])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_trigger, true_label, pi_golden = true_label_and_trigger(train_x=train_x,train_y=train_y,train_masks=train_masks,train_span=train_span,class_num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_golden[3][30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pi_star weighted by golden matrix (sum along axis 1):\n",
      "[0.7 0.5 0.3]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Giả sử bạn có các ma trận sau:\n",
    "# pi_star: Ma trận alignment (sau khi tính toán thông qua OT)\n",
    "pi_star = np.array([[0.3, 0.7, 0.1],\n",
    "                    [0.5, 0.4, 0.1],\n",
    "                    [0.2, 0.6, 0.3]])\n",
    "\n",
    "# pi_g: Ma trận golden (true trigger labels)\n",
    "pi_g = np.array([[0, 1, 0],  # w1 có nhãn đúng là t2\n",
    "                 [1, 0, 0],  # w2 có nhãn đúng là t1\n",
    "                 [0, 0, 1]]) # w3 có nhãn đúng là t3\n",
    "\n",
    "# Nhân ma trận pi_star với pi_g (theo từng phần tử)\n",
    "pi_star_weighted = pi_star * pi_g\n",
    "\n",
    "# Tính tổng theo chiều ngang (axis=1)\n",
    "pi_star_sum = pi_star_weighted.sum(axis=1)\n",
    "\n",
    "print(\"Pi_star weighted by golden matrix (sum along axis 1):\")\n",
    "print(pi_star_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pi_star_1 = torch.tensor([\n",
    "    [[0.3, 0.7, 0.1,-1.0], [0.5, 0.4, 0.1,-1.0], [0.2, 0.6, 0.3,-1.0]],\n",
    "    [[0.5, 0.4, 0.1,-2.0], [0.3, 0.7, 0.1,-2.0], [0.2, 0.6, 0.3,-2.0]]]\n",
    ")\n",
    "pi_star_2 = torch.tensor([\n",
    "    [[0.3, 0.7, 0.1,-1.0], [0.5, 0.4, 0.1,-1.0], [0.2, 0.6, 0.3,-1.0]],\n",
    "    [[0.5, 0.4, 0.1,-2.0], [0.3, 0.7, 0.1,-2.0], [0.2, 0.6, 0.3,-2.0]]]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6357)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def L_task(pi_star, y_true):\n",
    "    \"\"\"\n",
    "    Tính Loss Task (Negative Log-Likelihood Loss) cho mỗi batch dữ liệu.\n",
    "\n",
    "    Arguments:\n",
    "    - pi_star (Tensor): Tensor có kích thước (batch_size, seq_len), chứa xác suất dự đoán cho từng từ và nhãn.\n",
    "    - y_true (Tensor): Tensor có kích thước (batch_size, seq_len), chứa nhãn thực tế (labels) cho từng từ.\n",
    "\n",
    "    Return:\n",
    "    - loss (Tensor): giá trị loss trung bình cho cả batch.\n",
    "    \"\"\"\n",
    "\n",
    "    # Chỉ tính log của pi_star mà không có phần (1 - pi_star)\n",
    "    loss = -torch.log((torch.sum(pi_star*y_true,dim=-1))).mean()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "# Ví dụ sử dụng:\n",
    "batch_size = 2  # Số câu trong batch\n",
    "seq_len = 4  # Số từ trong mỗi câu\n",
    "\n",
    "# Giả sử chúng ta có xác suất pi_star và nhãn thực tế y_true cho mỗi câu trong batch\n",
    "pi_star = torch.tensor(\n",
    "    [\n",
    "        [[0.3, 0.7, 0.1, -1.0], [0.5, 0.4, 0.1, -1.0], [0.2, 0.6, 0.3, -1.0]],\n",
    "        [[0.5, 0.4, 0.1, -2.0], [0.3, 0.7, 0.1, -2.0], [0.2, 0.6, 0.3, -2.0]],\n",
    "    ]\n",
    ")\n",
    "\n",
    "y_true = torch.tensor(\n",
    "    [\n",
    "        [[0, 1, 0, 0], [1, 0, 0, 0], [0, 0, 1, 0]],\n",
    "        [[1, 0, 0, 0], [0, 1, 0, 0], [0, 1, 0, 0]],\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Tính L_task\n",
    "loss_task = L_task(pi_star, y_true)\n",
    "print(loss_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6357)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_probs = torch.sum(pi_star * y_true, dim=-1)\n",
    "log_probs = torch.log(log_probs + 1e-10)\n",
    "loss = -log_probs.mean()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6357)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-torch.log((torch.sum(pi_star*y_true,dim=-1))).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.0000, -0.3567, -0.0000,     nan],\n",
       "         [-0.6931, -0.0000, -0.0000,     nan],\n",
       "         [-0.0000, -0.0000, -1.2040,     nan]],\n",
       "\n",
       "        [[-0.6931, -0.0000, -0.0000,     nan],\n",
       "         [-0.0000, -0.3567, -0.0000,     nan],\n",
       "         [-0.0000, -0.5108, -0.0000,     nan]]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.log(pi_star)*y_true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "mul = -torch.log(pi_star_1*pi_star_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.4079,  0.7133,  4.6052, -0.0000],\n",
       "         [ 1.3863,  1.8326,  4.6052, -0.0000],\n",
       "         [ 3.2189,  1.0217,  2.4079, -0.0000]],\n",
       "\n",
       "        [[ 1.3863,  1.8326,  4.6052, -1.3863],\n",
       "         [ 2.4079,  0.7133,  4.6052, -1.3863],\n",
       "         [ 3.2189,  1.0217,  2.4079, -1.3863]]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8499, 1.5033])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mul.sum(dim=[1,2])/(mul.size(1)*mul.size(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_star.sum(dim=-1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_instance = {\n",
    "    \"piece_ids\": train_x[3],\n",
    "    \"label\": train_y[3],\n",
    "    \"span\": train_span[3],\n",
    "    \"mask\": train_masks[3],\n",
    "}\n",
    "# a, b = get_one_hot_true_label_and_true_trigger(data_instance=data_instance,num_label=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_word_is_label = torch.zeros(len(data_instance['piece_ids']),10)\n",
    "for i in range(len(data_instance[\"label\"])):\n",
    "    if data_instance[\"label\"][i] != 0:\n",
    "        # print(data_instance[\"label\"][i])\n",
    "\n",
    "    #     true_label.append(data_instance[\"label\"][i])\n",
    "    #     true_trigger.append(data_instance[\"span\"][i])\n",
    "        for word_is_trigger in data_instance['span'][i]:\n",
    "            # print(word_is_trigger)\n",
    "            matrix_word_is_label[word_is_trigger,data_instance['label'][i]] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_word_is_label[20:33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 1., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(train_span)):\n",
    "    print(train_span[i].size(-1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "test = [torch.tensor([[1,2,3],[4,5,6]]),torch.tensor([[7,8,9],[10,11,12]])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Giả sử bạn có các tensor sau:\n",
    "# `last_hidden_state` có kích thước [batch_size, seqlen, hidden_dim]\n",
    "last_hidden_state = torch.randn(4, 122, 768)  # Kích thước giả định\n",
    "\n",
    "# `mask` có kích thước [batch_size, seqlen], giá trị 1 cho token thực sự và 0 cho padding\n",
    "mask = torch.randint(0, 2, (4, 122))  # Ví dụ: 1 cho token thực sự, 0 cho padding\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_hidden_state_without_padding(last_hidden_state, masks):\n",
    "    masks = masks.unsqueeze(-1)\n",
    "    mask_hidden_state = last_hidden_state * masks\n",
    "    true_hidden_state_without_padding = mask_hidden_state.view(-1, 768)[\n",
    "        masks.view(-1) == 1\n",
    "    ]\n",
    "    return true_hidden_state_without_padding  # [sum_true_token, hidden_dim]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_embedding = get_true_hidden_state_without_padding(last_hidden_state,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_hidden_state = last_hidden_state * mask.unsqueeze(-1)\n",
    "masked_hidden_state.size()\n",
    "masked_hidden_state = masked_hidden_state.view(-1, 768)[mask.view(-1) == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([249, 768])"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "masked_hidden_state.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([249, 768])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_embedding.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giả sử bạn có các tensor như sau:\n",
    "batch_size = 4\n",
    "seq_len = 6\n",
    "\n",
    "# Các xác suất trigger cho từng token trong câu (p_wi)\n",
    "p_wi = torch.sigmoid(torch.randn(batch_size, seq_len))  # [4, 6]\n",
    "\n",
    "# Các nhãn thực tế (true_trig)\n",
    "true_trig = torch.randint(0, 2, (batch_size, seq_len))  # [4, 6] với giá trị 0 hoặc 1\n",
    "\n",
    "# Attention mask (masks), 1 cho token thực, 0 cho token padding\n",
    "masks = torch.tensor([[1, 1, 1, 1, 0, 0],  # Câu 1 có 4 token thực\n",
    "                      [1, 1, 1, 0, 0, 0],  # Câu 2 có 3 token thực\n",
    "                      [1, 1, 1, 1, 1, 0],  # Câu 3 có 5 token thực\n",
    "                      [1, 1, 1, 1, 1, 1]]) # Câu 4 có 6 token thực (không có padding)\n",
    "\n",
    "# Tính loss TI\n",
    "# loss = compute_loss_TI(p_wi, true_trig, masks)\n",
    "# print(\"Loss TI:\", loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8904, 0.4555, 0.2070])"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_wi[1][masks[1] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "seq_len = 5\n",
    "num_classes = 3\n",
    "\n",
    "# Tạo dữ liệu giả cho pi_star và pi_golden (giả sử xác suất phân bố đều cho pi_star, và pi_golden là các vector nhãn)\n",
    "pi_star = torch.rand(batch_size, seq_len, num_classes)  # Xác suất dự đoán ngẫu nhiên từ [0, 1]\n",
    "pi_star = pi_star / pi_star.sum(dim=-1, keepdim=True)  # Chuẩn hóa về tổng = 1 (xác suất)\n",
    "\n",
    "pi_golden = torch.randint(0, 2, (batch_size, seq_len, num_classes)).float()  # Nhãn thực (0 hoặc 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1151, 0.4943, 1.0000, 0.3761, 0.3852],\n",
       "        [0.4031, 0.7366, 1.0000, 0.8397, 0.1146],\n",
       "        [1.0000, 0.6542, 0.8769, 1.0000, 0.4036],\n",
       "        [0.8367, 0.6056, 0.7390, 0.0000, 0.3532]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.sum(pi_golden*pi_star,dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.0000, 0.1151, 0.0000],\n",
       "         [0.1963, 0.2979, 0.0000],\n",
       "         [0.2573, 0.4445, 0.2983],\n",
       "         [0.0000, 0.3761, 0.0000],\n",
       "         [0.0000, 0.3852, 0.0000]],\n",
       "\n",
       "        [[0.4031, 0.0000, 0.0000],\n",
       "         [0.0000, 0.3005, 0.4361],\n",
       "         [0.4377, 0.2548, 0.3074],\n",
       "         [0.3200, 0.0000, 0.5196],\n",
       "         [0.0246, 0.0000, 0.0900]],\n",
       "\n",
       "        [[0.2333, 0.3558, 0.4110],\n",
       "         [0.1819, 0.0000, 0.4723],\n",
       "         [0.6229, 0.0000, 0.2540],\n",
       "         [0.2883, 0.2216, 0.4901],\n",
       "         [0.0000, 0.0000, 0.4036]],\n",
       "\n",
       "        [[0.0000, 0.3779, 0.4588],\n",
       "         [0.0000, 0.6056, 0.0000],\n",
       "         [0.2351, 0.5038, 0.0000],\n",
       "         [0.0000, 0.0000, 0.0000],\n",
       "         [0.3532, 0.0000, 0.0000]]])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi_golden*pi_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn_pytorch(M, a, b, lambda_sh, numItermax=1000, stopThr=5e-3):\n",
    "    u = torch.ones_like(a) / a.size(0)\n",
    "    v = torch.zeros_like(b)\n",
    "    K = torch.exp(-M * lambda_sh)\n",
    "\n",
    "    cpt = 0\n",
    "    err = 1.0\n",
    "\n",
    "    def condition(cpt, u, v, err):\n",
    "        return cpt < numItermax and err > stopThr\n",
    "\n",
    "    def v_update(u, v):\n",
    "        v = b / torch.matmul(K.t(), u)\n",
    "        u = a / torch.matmul(K, v)\n",
    "        return u, v\n",
    "\n",
    "    def no_v_update(u, v):\n",
    "        return u, v\n",
    "\n",
    "    def err_f1(K, u, v, b):\n",
    "        bb = v * torch.matmul(K.t(), u)\n",
    "        err = torch.norm(torch.sum(torch.abs(bb - b), dim=0), p=float('inf'))\n",
    "        return err\n",
    "\n",
    "    def err_f2(err):\n",
    "        return err\n",
    "\n",
    "    def loop_func(cpt, u, v, err):\n",
    "        u = a / torch.matmul(K, b / torch.matmul(u.T, K).T)\n",
    "        cpt = cpt + 1\n",
    "        if cpt % 20 == 1 or cpt == numItermax:\n",
    "            u, v = v_update(u, v)\n",
    "            err = err_f1(K, u, v, b)\n",
    "        else:\n",
    "            u, v = no_v_update(u, v)\n",
    "            err = err_f2(err)\n",
    "        return cpt, u, v, err\n",
    "\n",
    "    while condition(cpt, u, v, err):\n",
    "        cpt, u, v, err = loop_func(cpt, u, v, err)\n",
    "\n",
    "    sinkhorn_divergences = torch.sum(u * torch.matmul(K * M, v), dim=0)\n",
    "    return sinkhorn_divergences\n",
    "\n",
    "def compute_pi_star(M, a, b, lambda_sh, numItermax=1000, stopThr=5e-3):\n",
    "    # Gọi hàm Sinkhorn để tính u, v và ma trận K\n",
    "    u, v, K = sinkhorn_pytorch(M, a, b, lambda_sh, numItermax, stopThr)\n",
    "    \n",
    "    # Tính ma trận đồng nhất tối ưu pi_star bằng công thức pi_star = diag(u) * K * diag(v)\n",
    "    pi_star = torch.diag(u) @ K @ torch.diag(v)\n",
    "    \n",
    "    return pi_star\n",
    "\n",
    "# batch_size = 4\n",
    "# num_class = 11\n",
    "# num_token = 122\n",
    "\n",
    "# word_preference = torch.randn(batch_size,num_token)\n",
    "# type_preference = torch.randn(batch_size,num_class)\n",
    "# cost_matrix = torch.randn(batch_size,num_class,num_token)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_class, num_token = 11, 122\n",
    "\n",
    "# Tạo ma trận chi phí ngẫu nhiên kích thước (n, m) = (11, 122)\n",
    "M = torch.rand(num_class, num_token)\n",
    "\n",
    "# Tạo các vector a và b là phân phối xác suất (tổng = 1)\n",
    "a = torch.tensor([1.0 / num_class] * num_class)  # Phân phối xác suất cho a (có tổng = 1)\n",
    "b = torch.tensor([1.0 / num_token] * num_token)  # Phân phối xác suất cho b (có tổng = 1)\n",
    "\n",
    "# Tham số điều chỉnh regularization\n",
    "lambda_sh = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 122, 11, 768])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn([4,122,768])\n",
    "y = torch.randn([11,768])\n",
    "(x.unsqueeze(2)-y.unsqueeze(0).unsqueeze(0)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1=x.unsqueeze(2).repeat(1,1,11,1)\n",
    "y1=y.unsqueeze(0).unsqueeze(0).repeat(4,122,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 122, 11])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-torch.nn.functional.cosine_similarity(x1=x1,x2=y1,dim=3)).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "test = torch.randint(1,20,(4,11,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 8, 1, 12, 7, 5, 17, 16, 11, 14, 13, 15, 6]"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(dict.fromkeys(test[0].flatten().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 8, 1, 12, 7, 1, 5, 17, 16, 11, 14, 1, 13, 5, 11, 5, 15, 2, 17, 6, 11, 1]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[0].flatten().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [2, 2, 8, 8, 1, 1, 12, 13, 7, 5, 17, 16, 11, 14, 13, 15, 6]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "natmin",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
